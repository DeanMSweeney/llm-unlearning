12/04/2025 14:31:47 - INFO - __main__ - Initialized tokenizer
12/04/2025 14:31:47 - INFO - __main__ - Found 5 models to evaluate.
12/04/2025 14:31:47 - INFO - __main__ - Constructing StereoSet dataloaders
12/04/2025 14:31:48 - INFO - __main__ - Constructed StereoSet dataloaders
12/04/2025 14:31:48 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3
12/04/2025 14:31:48 - INFO - __main__ - ==================================================1/5==================================================
12/04/2025 14:31:50 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
    "gender": {
        "dev": {
            "ss": 0.6349206349206349,
            "lms": 0.8650793650793651,
            "icat": 0.6316452506928698
        },
        "test": {
            "ss": 0.5625,
            "lms": 0.8359375,
            "icat": 0.7314453125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.43891402714932126,
            "lms": 0.8574660633484162,
            "icat": 0.7527077660162568
        },
        "test": {
            "ss": 0.5294117647058824,
            "lms": 0.8755656108597285,
            "icat": 0.8240617513973916
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.577922077922078,
            "lms": 0.8295454545454546,
            "icat": 0.7002656434474617
        },
        "test": {
            "ss": 0.5292207792207793,
            "lms": 0.8068181818181818,
            "icat": 0.7596664698937425
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.6190476190476191,
            "lms": 0.7380952380952381,
            "icat": 0.562358276643991
        },
        "test": {
            "ss": 0.6363636363636364,
            "lms": 0.8181818181818182,
            "icat": 0.5950413223140496
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 14:31:50 - INFO - __main__ - ====================================================================================================
12/04/2025 14:31:50 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_5
12/04/2025 14:31:50 - INFO - __main__ - ==================================================2/5==================================================
12/04/2025 14:31:51 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_5",
    "gender": {
        "dev": {
            "ss": 0.6349206349206349,
            "lms": 0.8333333333333334,
            "icat": 0.6084656084656086
        },
        "test": {
            "ss": 0.546875,
            "lms": 0.8125,
            "icat": 0.736328125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.45248868778280543,
            "lms": 0.832579185520362,
            "icat": 0.7534653262627711
        },
        "test": {
            "ss": 0.5294117647058824,
            "lms": 0.8461538461538461,
            "icat": 0.7963800904977375
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.5746753246753247,
            "lms": 0.8133116883116883,
            "icat": 0.6918430595378647
        },
        "test": {
            "ss": 0.5422077922077922,
            "lms": 0.797077922077922,
            "icat": 0.7297921234609546
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.5714285714285714,
            "lms": 0.6904761904761905,
            "icat": 0.5918367346938775
        },
        "test": {
            "ss": 0.5909090909090909,
            "lms": 0.8181818181818182,
            "icat": 0.6694214876033058
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 14:31:51 - INFO - __main__ - ====================================================================================================
12/04/2025 14:31:51 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_4
12/04/2025 14:31:51 - INFO - __main__ - ==================================================3/5==================================================
12/04/2025 14:31:52 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_4",
    "gender": {
        "dev": {
            "ss": 0.6349206349206349,
            "lms": 0.8492063492063492,
            "icat": 0.6200554295792392
        },
        "test": {
            "ss": 0.546875,
            "lms": 0.828125,
            "icat": 0.75048828125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.43891402714932126,
            "lms": 0.834841628959276,
            "icat": 0.7328474027968306
        },
        "test": {
            "ss": 0.5248868778280543,
            "lms": 0.8619909502262444,
            "icat": 0.8190864232919064
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.5746753246753247,
            "lms": 0.8165584415584416,
            "icat": 0.694604908078934
        },
        "test": {
            "ss": 0.5324675324675324,
            "lms": 0.8035714285714286,
            "icat": 0.7513914656771801
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.5714285714285714,
            "lms": 0.6904761904761905,
            "icat": 0.5918367346938775
        },
        "test": {
            "ss": 0.5909090909090909,
            "lms": 0.8409090909090909,
            "icat": 0.6880165289256198
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 14:31:52 - INFO - __main__ - ====================================================================================================
12/04/2025 14:31:52 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_1
12/04/2025 14:31:52 - INFO - __main__ - ==================================================4/5==================================================
12/04/2025 14:31:53 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_1",
    "gender": {
        "dev": {
            "ss": 0.6507936507936508,
            "lms": 0.8968253968253969,
            "icat": 0.6263542454018645
        },
        "test": {
            "ss": 0.59375,
            "lms": 0.8671875,
            "icat": 0.70458984375
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.46153846153846156,
            "lms": 0.8868778280542986,
            "icat": 0.8186564566655065
        },
        "test": {
            "ss": 0.5475113122171946,
            "lms": 0.8800904977375565,
            "icat": 0.796461988902766
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.5097402597402597,
            "lms": 0.8522727272727273,
            "icat": 0.8356700118063755
        },
        "test": {
            "ss": 0.487012987012987,
            "lms": 0.8441558441558441,
            "icat": 0.8222297183336144
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.5714285714285714,
            "lms": 0.7619047619047619,
            "icat": 0.653061224489796
        },
        "test": {
            "ss": 0.45454545454545453,
            "lms": 0.8409090909090909,
            "icat": 0.7644628099173554
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 14:31:53 - INFO - __main__ - ====================================================================================================
12/04/2025 14:31:53 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_2
12/04/2025 14:31:53 - INFO - __main__ - ==================================================5/5==================================================
12/04/2025 14:31:54 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_2",
    "gender": {
        "dev": {
            "ss": 0.6190476190476191,
            "lms": 0.8650793650793651,
            "icat": 0.6591080876795162
        },
        "test": {
            "ss": 0.5625,
            "lms": 0.875,
            "icat": 0.765625
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4434389140271493,
            "lms": 0.8733031674208145,
            "icat": 0.7745132163551115
        },
        "test": {
            "ss": 0.5384615384615384,
            "lms": 0.8868778280542986,
            "icat": 0.8186564566655065
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.5422077922077922,
            "lms": 0.8344155844155844,
            "icat": 0.7639779052116713
        },
        "test": {
            "ss": 0.5032467532467533,
            "lms": 0.827922077922078,
            "icat": 0.8225459605329735
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.5714285714285714,
            "lms": 0.7142857142857143,
            "icat": 0.6122448979591837
        },
        "test": {
            "ss": 0.6363636363636364,
            "lms": 0.8409090909090909,
            "icat": 0.6115702479338844
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 14:31:54 - INFO - __main__ - ====================================================================================================
12/04/2025 14:31:54 - INFO - __main__ - Got results map {
    "full_grad": {
        "inp": {
            "adv": {
                "1e-05": {
                    "64": {
                        "None": {
                            "model_3": {
                                "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6349206349206349,
                                        "lms": 0.8650793650793651,
                                        "icat": 0.6316452506928698
                                    },
                                    "test": {
                                        "ss": 0.5625,
                                        "lms": 0.8359375,
                                        "icat": 0.7314453125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.43891402714932126,
                                        "lms": 0.8574660633484162,
                                        "icat": 0.7527077660162568
                                    },
                                    "test": {
                                        "ss": 0.5294117647058824,
                                        "lms": 0.8755656108597285,
                                        "icat": 0.8240617513973916
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.577922077922078,
                                        "lms": 0.8295454545454546,
                                        "icat": 0.7002656434474617
                                    },
                                    "test": {
                                        "ss": 0.5292207792207793,
                                        "lms": 0.8068181818181818,
                                        "icat": 0.7596664698937425
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.6190476190476191,
                                        "lms": 0.7380952380952381,
                                        "icat": 0.562358276643991
                                    },
                                    "test": {
                                        "ss": 0.6363636363636364,
                                        "lms": 0.8181818181818182,
                                        "icat": 0.5950413223140496
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_5": {
                                "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_5",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6349206349206349,
                                        "lms": 0.8333333333333334,
                                        "icat": 0.6084656084656086
                                    },
                                    "test": {
                                        "ss": 0.546875,
                                        "lms": 0.8125,
                                        "icat": 0.736328125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.45248868778280543,
                                        "lms": 0.832579185520362,
                                        "icat": 0.7534653262627711
                                    },
                                    "test": {
                                        "ss": 0.5294117647058824,
                                        "lms": 0.8461538461538461,
                                        "icat": 0.7963800904977375
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.5746753246753247,
                                        "lms": 0.8133116883116883,
                                        "icat": 0.6918430595378647
                                    },
                                    "test": {
                                        "ss": 0.5422077922077922,
                                        "lms": 0.797077922077922,
                                        "icat": 0.7297921234609546
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.5714285714285714,
                                        "lms": 0.6904761904761905,
                                        "icat": 0.5918367346938775
                                    },
                                    "test": {
                                        "ss": 0.5909090909090909,
                                        "lms": 0.8181818181818182,
                                        "icat": 0.6694214876033058
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_4": {
                                "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_4",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6349206349206349,
                                        "lms": 0.8492063492063492,
                                        "icat": 0.6200554295792392
                                    },
                                    "test": {
                                        "ss": 0.546875,
                                        "lms": 0.828125,
                                        "icat": 0.75048828125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.43891402714932126,
                                        "lms": 0.834841628959276,
                                        "icat": 0.7328474027968306
                                    },
                                    "test": {
                                        "ss": 0.5248868778280543,
                                        "lms": 0.8619909502262444,
                                        "icat": 0.8190864232919064
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.5746753246753247,
                                        "lms": 0.8165584415584416,
                                        "icat": 0.694604908078934
                                    },
                                    "test": {
                                        "ss": 0.5324675324675324,
                                        "lms": 0.8035714285714286,
                                        "icat": 0.7513914656771801
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.5714285714285714,
                                        "lms": 0.6904761904761905,
                                        "icat": 0.5918367346938775
                                    },
                                    "test": {
                                        "ss": 0.5909090909090909,
                                        "lms": 0.8409090909090909,
                                        "icat": 0.6880165289256198
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_1": {
                                "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_1",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6507936507936508,
                                        "lms": 0.8968253968253969,
                                        "icat": 0.6263542454018645
                                    },
                                    "test": {
                                        "ss": 0.59375,
                                        "lms": 0.8671875,
                                        "icat": 0.70458984375
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.46153846153846156,
                                        "lms": 0.8868778280542986,
                                        "icat": 0.8186564566655065
                                    },
                                    "test": {
                                        "ss": 0.5475113122171946,
                                        "lms": 0.8800904977375565,
                                        "icat": 0.796461988902766
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.5097402597402597,
                                        "lms": 0.8522727272727273,
                                        "icat": 0.8356700118063755
                                    },
                                    "test": {
                                        "ss": 0.487012987012987,
                                        "lms": 0.8441558441558441,
                                        "icat": 0.8222297183336144
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.5714285714285714,
                                        "lms": 0.7619047619047619,
                                        "icat": 0.653061224489796
                                    },
                                    "test": {
                                        "ss": 0.45454545454545453,
                                        "lms": 0.8409090909090909,
                                        "icat": 0.7644628099173554
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_2": {
                                "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_2",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6190476190476191,
                                        "lms": 0.8650793650793651,
                                        "icat": 0.6591080876795162
                                    },
                                    "test": {
                                        "ss": 0.5625,
                                        "lms": 0.875,
                                        "icat": 0.765625
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4434389140271493,
                                        "lms": 0.8733031674208145,
                                        "icat": 0.7745132163551115
                                    },
                                    "test": {
                                        "ss": 0.5384615384615384,
                                        "lms": 0.8868778280542986,
                                        "icat": 0.8186564566655065
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.5422077922077922,
                                        "lms": 0.8344155844155844,
                                        "icat": 0.7639779052116713
                                    },
                                    "test": {
                                        "ss": 0.5032467532467533,
                                        "lms": 0.827922077922078,
                                        "icat": 0.8225459605329735
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.5714285714285714,
                                        "lms": 0.7142857142857143,
                                        "icat": 0.6122448979591837
                                    },
                                    "test": {
                                        "ss": 0.6363636363636364,
                                        "lms": 0.8409090909090909,
                                        "icat": 0.6115702479338844
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}
12/04/2025 14:31:54 - INFO - __main__ - Got best results {
    "best_model": {
        "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
        "gender": {
            "dev": {
                "ss": 0.6349206349206349,
                "lms": 0.8650793650793651,
                "icat": 0.6316452506928698
            },
            "test": {
                "ss": 0.5625,
                "lms": 0.8359375,
                "icat": 0.7314453125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.43891402714932126,
                "lms": 0.8574660633484162,
                "icat": 0.7527077660162568
            },
            "test": {
                "ss": 0.5294117647058824,
                "lms": 0.8755656108597285,
                "icat": 0.8240617513973916
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.577922077922078,
                "lms": 0.8295454545454546,
                "icat": 0.7002656434474617
            },
            "test": {
                "ss": 0.5292207792207793,
                "lms": 0.8068181818181818,
                "icat": 0.7596664698937425
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.6190476190476191,
                "lms": 0.7380952380952381,
                "icat": 0.562358276643991
            },
            "test": {
                "ss": 0.6363636363636364,
                "lms": 0.8181818181818182,
                "icat": 0.5950413223140496
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4823943661971831,
        "test_criterion_score": -0.5368421052631579
    },
    "full_grad": {
        "best_model": {
            "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
            "gender": {
                "dev": {
                    "ss": 0.6349206349206349,
                    "lms": 0.8650793650793651,
                    "icat": 0.6316452506928698
                },
                "test": {
                    "ss": 0.5625,
                    "lms": 0.8359375,
                    "icat": 0.7314453125
                },
                "dev_count": 189,
                "test_count": 192
            },
            "profession": {
                "dev": {
                    "ss": 0.43891402714932126,
                    "lms": 0.8574660633484162,
                    "icat": 0.7527077660162568
                },
                "test": {
                    "ss": 0.5294117647058824,
                    "lms": 0.8755656108597285,
                    "icat": 0.8240617513973916
                },
                "dev_count": 663,
                "test_count": 663
            },
            "race": {
                "dev": {
                    "ss": 0.577922077922078,
                    "lms": 0.8295454545454546,
                    "icat": 0.7002656434474617
                },
                "test": {
                    "ss": 0.5292207792207793,
                    "lms": 0.8068181818181818,
                    "icat": 0.7596664698937425
                },
                "dev_count": 924,
                "test_count": 924
            },
            "religion": {
                "dev": {
                    "ss": 0.6190476190476191,
                    "lms": 0.7380952380952381,
                    "icat": 0.562358276643991
                },
                "test": {
                    "ss": 0.6363636363636364,
                    "lms": 0.8181818181818182,
                    "icat": 0.5950413223140496
                },
                "dev_count": 63,
                "test_count": 66
            },
            "dev_criterion_score": -0.4823943661971831,
            "test_criterion_score": -0.5368421052631579
        },
        "inp": {
            "best_model": {
                "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
                "gender": {
                    "dev": {
                        "ss": 0.6349206349206349,
                        "lms": 0.8650793650793651,
                        "icat": 0.6316452506928698
                    },
                    "test": {
                        "ss": 0.5625,
                        "lms": 0.8359375,
                        "icat": 0.7314453125
                    },
                    "dev_count": 189,
                    "test_count": 192
                },
                "profession": {
                    "dev": {
                        "ss": 0.43891402714932126,
                        "lms": 0.8574660633484162,
                        "icat": 0.7527077660162568
                    },
                    "test": {
                        "ss": 0.5294117647058824,
                        "lms": 0.8755656108597285,
                        "icat": 0.8240617513973916
                    },
                    "dev_count": 663,
                    "test_count": 663
                },
                "race": {
                    "dev": {
                        "ss": 0.577922077922078,
                        "lms": 0.8295454545454546,
                        "icat": 0.7002656434474617
                    },
                    "test": {
                        "ss": 0.5292207792207793,
                        "lms": 0.8068181818181818,
                        "icat": 0.7596664698937425
                    },
                    "dev_count": 924,
                    "test_count": 924
                },
                "religion": {
                    "dev": {
                        "ss": 0.6190476190476191,
                        "lms": 0.7380952380952381,
                        "icat": 0.562358276643991
                    },
                    "test": {
                        "ss": 0.6363636363636364,
                        "lms": 0.8181818181818182,
                        "icat": 0.5950413223140496
                    },
                    "dev_count": 63,
                    "test_count": 66
                },
                "dev_criterion_score": -0.4823943661971831,
                "test_criterion_score": -0.5368421052631579
            },
            "adv": {
                "best_model": {
                    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
                    "gender": {
                        "dev": {
                            "ss": 0.6349206349206349,
                            "lms": 0.8650793650793651,
                            "icat": 0.6316452506928698
                        },
                        "test": {
                            "ss": 0.5625,
                            "lms": 0.8359375,
                            "icat": 0.7314453125
                        },
                        "dev_count": 189,
                        "test_count": 192
                    },
                    "profession": {
                        "dev": {
                            "ss": 0.43891402714932126,
                            "lms": 0.8574660633484162,
                            "icat": 0.7527077660162568
                        },
                        "test": {
                            "ss": 0.5294117647058824,
                            "lms": 0.8755656108597285,
                            "icat": 0.8240617513973916
                        },
                        "dev_count": 663,
                        "test_count": 663
                    },
                    "race": {
                        "dev": {
                            "ss": 0.577922077922078,
                            "lms": 0.8295454545454546,
                            "icat": 0.7002656434474617
                        },
                        "test": {
                            "ss": 0.5292207792207793,
                            "lms": 0.8068181818181818,
                            "icat": 0.7596664698937425
                        },
                        "dev_count": 924,
                        "test_count": 924
                    },
                    "religion": {
                        "dev": {
                            "ss": 0.6190476190476191,
                            "lms": 0.7380952380952381,
                            "icat": 0.562358276643991
                        },
                        "test": {
                            "ss": 0.6363636363636364,
                            "lms": 0.8181818181818182,
                            "icat": 0.5950413223140496
                        },
                        "dev_count": 63,
                        "test_count": 66
                    },
                    "dev_criterion_score": -0.4823943661971831,
                    "test_criterion_score": -0.5368421052631579
                },
                "1e-05": {
                    "best_model": {
                        "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
                        "gender": {
                            "dev": {
                                "ss": 0.6349206349206349,
                                "lms": 0.8650793650793651,
                                "icat": 0.6316452506928698
                            },
                            "test": {
                                "ss": 0.5625,
                                "lms": 0.8359375,
                                "icat": 0.7314453125
                            },
                            "dev_count": 189,
                            "test_count": 192
                        },
                        "profession": {
                            "dev": {
                                "ss": 0.43891402714932126,
                                "lms": 0.8574660633484162,
                                "icat": 0.7527077660162568
                            },
                            "test": {
                                "ss": 0.5294117647058824,
                                "lms": 0.8755656108597285,
                                "icat": 0.8240617513973916
                            },
                            "dev_count": 663,
                            "test_count": 663
                        },
                        "race": {
                            "dev": {
                                "ss": 0.577922077922078,
                                "lms": 0.8295454545454546,
                                "icat": 0.7002656434474617
                            },
                            "test": {
                                "ss": 0.5292207792207793,
                                "lms": 0.8068181818181818,
                                "icat": 0.7596664698937425
                            },
                            "dev_count": 924,
                            "test_count": 924
                        },
                        "religion": {
                            "dev": {
                                "ss": 0.6190476190476191,
                                "lms": 0.7380952380952381,
                                "icat": 0.562358276643991
                            },
                            "test": {
                                "ss": 0.6363636363636364,
                                "lms": 0.8181818181818182,
                                "icat": 0.5950413223140496
                            },
                            "dev_count": 63,
                            "test_count": 66
                        },
                        "dev_criterion_score": -0.4823943661971831,
                        "test_criterion_score": -0.5368421052631579
                    },
                    "64": {
                        "best_model": {
                            "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
                            "gender": {
                                "dev": {
                                    "ss": 0.6349206349206349,
                                    "lms": 0.8650793650793651,
                                    "icat": 0.6316452506928698
                                },
                                "test": {
                                    "ss": 0.5625,
                                    "lms": 0.8359375,
                                    "icat": 0.7314453125
                                },
                                "dev_count": 189,
                                "test_count": 192
                            },
                            "profession": {
                                "dev": {
                                    "ss": 0.43891402714932126,
                                    "lms": 0.8574660633484162,
                                    "icat": 0.7527077660162568
                                },
                                "test": {
                                    "ss": 0.5294117647058824,
                                    "lms": 0.8755656108597285,
                                    "icat": 0.8240617513973916
                                },
                                "dev_count": 663,
                                "test_count": 663
                            },
                            "race": {
                                "dev": {
                                    "ss": 0.577922077922078,
                                    "lms": 0.8295454545454546,
                                    "icat": 0.7002656434474617
                                },
                                "test": {
                                    "ss": 0.5292207792207793,
                                    "lms": 0.8068181818181818,
                                    "icat": 0.7596664698937425
                                },
                                "dev_count": 924,
                                "test_count": 924
                            },
                            "religion": {
                                "dev": {
                                    "ss": 0.6190476190476191,
                                    "lms": 0.7380952380952381,
                                    "icat": 0.562358276643991
                                },
                                "test": {
                                    "ss": 0.6363636363636364,
                                    "lms": 0.8181818181818182,
                                    "icat": 0.5950413223140496
                                },
                                "dev_count": 63,
                                "test_count": 66
                            },
                            "dev_criterion_score": -0.4823943661971831,
                            "test_criterion_score": -0.5368421052631579
                        },
                        "None": {
                            "best_model": {
                                "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6349206349206349,
                                        "lms": 0.8650793650793651,
                                        "icat": 0.6316452506928698
                                    },
                                    "test": {
                                        "ss": 0.5625,
                                        "lms": 0.8359375,
                                        "icat": 0.7314453125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.43891402714932126,
                                        "lms": 0.8574660633484162,
                                        "icat": 0.7527077660162568
                                    },
                                    "test": {
                                        "ss": 0.5294117647058824,
                                        "lms": 0.8755656108597285,
                                        "icat": 0.8240617513973916
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.577922077922078,
                                        "lms": 0.8295454545454546,
                                        "icat": 0.7002656434474617
                                    },
                                    "test": {
                                        "ss": 0.5292207792207793,
                                        "lms": 0.8068181818181818,
                                        "icat": 0.7596664698937425
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.6190476190476191,
                                        "lms": 0.7380952380952381,
                                        "icat": 0.562358276643991
                                    },
                                    "test": {
                                        "ss": 0.6363636363636364,
                                        "lms": 0.8181818181818182,
                                        "icat": 0.5950413223140496
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                },
                                "dev_criterion_score": -0.4823943661971831,
                                "test_criterion_score": -0.5368421052631579
                            },
                            "model_3": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6349206349206349,
                                            "lms": 0.8650793650793651,
                                            "icat": 0.6316452506928698
                                        },
                                        "test": {
                                            "ss": 0.5625,
                                            "lms": 0.8359375,
                                            "icat": 0.7314453125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.43891402714932126,
                                            "lms": 0.8574660633484162,
                                            "icat": 0.7527077660162568
                                        },
                                        "test": {
                                            "ss": 0.5294117647058824,
                                            "lms": 0.8755656108597285,
                                            "icat": 0.8240617513973916
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.577922077922078,
                                            "lms": 0.8295454545454546,
                                            "icat": 0.7002656434474617
                                        },
                                        "test": {
                                            "ss": 0.5292207792207793,
                                            "lms": 0.8068181818181818,
                                            "icat": 0.7596664698937425
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.6190476190476191,
                                            "lms": 0.7380952380952381,
                                            "icat": 0.562358276643991
                                        },
                                        "test": {
                                            "ss": 0.6363636363636364,
                                            "lms": 0.8181818181818182,
                                            "icat": 0.5950413223140496
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4823943661971831,
                                    "test_criterion_score": -0.5368421052631579
                                }
                            },
                            "model_5": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_5",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6349206349206349,
                                            "lms": 0.8333333333333334,
                                            "icat": 0.6084656084656086
                                        },
                                        "test": {
                                            "ss": 0.546875,
                                            "lms": 0.8125,
                                            "icat": 0.736328125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.45248868778280543,
                                            "lms": 0.832579185520362,
                                            "icat": 0.7534653262627711
                                        },
                                        "test": {
                                            "ss": 0.5294117647058824,
                                            "lms": 0.8461538461538461,
                                            "icat": 0.7963800904977375
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.5746753246753247,
                                            "lms": 0.8133116883116883,
                                            "icat": 0.6918430595378647
                                        },
                                        "test": {
                                            "ss": 0.5422077922077922,
                                            "lms": 0.797077922077922,
                                            "icat": 0.7297921234609546
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.5714285714285714,
                                            "lms": 0.6904761904761905,
                                            "icat": 0.5918367346938775
                                        },
                                        "test": {
                                            "ss": 0.5909090909090909,
                                            "lms": 0.8181818181818182,
                                            "icat": 0.6694214876033058
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.49295774647887325,
                                    "test_criterion_score": -0.5333333333333333
                                }
                            },
                            "model_4": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_4",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6349206349206349,
                                            "lms": 0.8492063492063492,
                                            "icat": 0.6200554295792392
                                        },
                                        "test": {
                                            "ss": 0.546875,
                                            "lms": 0.828125,
                                            "icat": 0.75048828125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.43891402714932126,
                                            "lms": 0.834841628959276,
                                            "icat": 0.7328474027968306
                                        },
                                        "test": {
                                            "ss": 0.5248868778280543,
                                            "lms": 0.8619909502262444,
                                            "icat": 0.8190864232919064
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.5746753246753247,
                                            "lms": 0.8165584415584416,
                                            "icat": 0.694604908078934
                                        },
                                        "test": {
                                            "ss": 0.5324675324675324,
                                            "lms": 0.8035714285714286,
                                            "icat": 0.7513914656771801
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.5714285714285714,
                                            "lms": 0.6904761904761905,
                                            "icat": 0.5918367346938775
                                        },
                                        "test": {
                                            "ss": 0.5909090909090909,
                                            "lms": 0.8409090909090909,
                                            "icat": 0.6880165289256198
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4823943661971831,
                                    "test_criterion_score": -0.5298245614035088
                                }
                            },
                            "model_1": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_1",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6507936507936508,
                                            "lms": 0.8968253968253969,
                                            "icat": 0.6263542454018645
                                        },
                                        "test": {
                                            "ss": 0.59375,
                                            "lms": 0.8671875,
                                            "icat": 0.70458984375
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.46153846153846156,
                                            "lms": 0.8868778280542986,
                                            "icat": 0.8186564566655065
                                        },
                                        "test": {
                                            "ss": 0.5475113122171946,
                                            "lms": 0.8800904977375565,
                                            "icat": 0.796461988902766
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.5097402597402597,
                                            "lms": 0.8522727272727273,
                                            "icat": 0.8356700118063755
                                        },
                                        "test": {
                                            "ss": 0.487012987012987,
                                            "lms": 0.8441558441558441,
                                            "icat": 0.8222297183336144
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.5714285714285714,
                                            "lms": 0.7619047619047619,
                                            "icat": 0.653061224489796
                                        },
                                        "test": {
                                            "ss": 0.45454545454545453,
                                            "lms": 0.8409090909090909,
                                            "icat": 0.7644628099173554
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.5035211267605634,
                                    "test_criterion_score": -0.5578947368421053
                                }
                            },
                            "model_2": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_2",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6190476190476191,
                                            "lms": 0.8650793650793651,
                                            "icat": 0.6591080876795162
                                        },
                                        "test": {
                                            "ss": 0.5625,
                                            "lms": 0.875,
                                            "icat": 0.765625
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4434389140271493,
                                            "lms": 0.8733031674208145,
                                            "icat": 0.7745132163551115
                                        },
                                        "test": {
                                            "ss": 0.5384615384615384,
                                            "lms": 0.8868778280542986,
                                            "icat": 0.8186564566655065
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.5422077922077922,
                                            "lms": 0.8344155844155844,
                                            "icat": 0.7639779052116713
                                        },
                                        "test": {
                                            "ss": 0.5032467532467533,
                                            "lms": 0.827922077922078,
                                            "icat": 0.8225459605329735
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.5714285714285714,
                                            "lms": 0.7142857142857143,
                                            "icat": 0.6122448979591837
                                        },
                                        "test": {
                                            "ss": 0.6363636363636364,
                                            "lms": 0.8409090909090909,
                                            "icat": 0.6115702479338844
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4823943661971831,
                                    "test_criterion_score": -0.543859649122807
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}
12/04/2025 14:31:54 - INFO - __main__ - Got all results {
    "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3": {
        "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_3",
        "gender": {
            "dev": {
                "ss": 0.6349206349206349,
                "lms": 0.8650793650793651,
                "icat": 0.6316452506928698
            },
            "test": {
                "ss": 0.5625,
                "lms": 0.8359375,
                "icat": 0.7314453125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.43891402714932126,
                "lms": 0.8574660633484162,
                "icat": 0.7527077660162568
            },
            "test": {
                "ss": 0.5294117647058824,
                "lms": 0.8755656108597285,
                "icat": 0.8240617513973916
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.577922077922078,
                "lms": 0.8295454545454546,
                "icat": 0.7002656434474617
            },
            "test": {
                "ss": 0.5292207792207793,
                "lms": 0.8068181818181818,
                "icat": 0.7596664698937425
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.6190476190476191,
                "lms": 0.7380952380952381,
                "icat": 0.562358276643991
            },
            "test": {
                "ss": 0.6363636363636364,
                "lms": 0.8181818181818182,
                "icat": 0.5950413223140496
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4823943661971831,
        "test_criterion_score": -0.5368421052631579
    },
    "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_5": {
        "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_5",
        "gender": {
            "dev": {
                "ss": 0.6349206349206349,
                "lms": 0.8333333333333334,
                "icat": 0.6084656084656086
            },
            "test": {
                "ss": 0.546875,
                "lms": 0.8125,
                "icat": 0.736328125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.45248868778280543,
                "lms": 0.832579185520362,
                "icat": 0.7534653262627711
            },
            "test": {
                "ss": 0.5294117647058824,
                "lms": 0.8461538461538461,
                "icat": 0.7963800904977375
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.5746753246753247,
                "lms": 0.8133116883116883,
                "icat": 0.6918430595378647
            },
            "test": {
                "ss": 0.5422077922077922,
                "lms": 0.797077922077922,
                "icat": 0.7297921234609546
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.5714285714285714,
                "lms": 0.6904761904761905,
                "icat": 0.5918367346938775
            },
            "test": {
                "ss": 0.5909090909090909,
                "lms": 0.8181818181818182,
                "icat": 0.6694214876033058
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.49295774647887325,
        "test_criterion_score": -0.5333333333333333
    },
    "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_4": {
        "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_4",
        "gender": {
            "dev": {
                "ss": 0.6349206349206349,
                "lms": 0.8492063492063492,
                "icat": 0.6200554295792392
            },
            "test": {
                "ss": 0.546875,
                "lms": 0.828125,
                "icat": 0.75048828125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.43891402714932126,
                "lms": 0.834841628959276,
                "icat": 0.7328474027968306
            },
            "test": {
                "ss": 0.5248868778280543,
                "lms": 0.8619909502262444,
                "icat": 0.8190864232919064
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.5746753246753247,
                "lms": 0.8165584415584416,
                "icat": 0.694604908078934
            },
            "test": {
                "ss": 0.5324675324675324,
                "lms": 0.8035714285714286,
                "icat": 0.7513914656771801
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.5714285714285714,
                "lms": 0.6904761904761905,
                "icat": 0.5918367346938775
            },
            "test": {
                "ss": 0.5909090909090909,
                "lms": 0.8409090909090909,
                "icat": 0.6880165289256198
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4823943661971831,
        "test_criterion_score": -0.5298245614035088
    },
    "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_1": {
        "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_1",
        "gender": {
            "dev": {
                "ss": 0.6507936507936508,
                "lms": 0.8968253968253969,
                "icat": 0.6263542454018645
            },
            "test": {
                "ss": 0.59375,
                "lms": 0.8671875,
                "icat": 0.70458984375
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.46153846153846156,
                "lms": 0.8868778280542986,
                "icat": 0.8186564566655065
            },
            "test": {
                "ss": 0.5475113122171946,
                "lms": 0.8800904977375565,
                "icat": 0.796461988902766
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.5097402597402597,
                "lms": 0.8522727272727273,
                "icat": 0.8356700118063755
            },
            "test": {
                "ss": 0.487012987012987,
                "lms": 0.8441558441558441,
                "icat": 0.8222297183336144
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.5714285714285714,
                "lms": 0.7619047619047619,
                "icat": 0.653061224489796
            },
            "test": {
                "ss": 0.45454545454545453,
                "lms": 0.8409090909090909,
                "icat": 0.7644628099173554
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.5035211267605634,
        "test_criterion_score": -0.5578947368421053
    },
    "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_2": {
        "path": "./models/bert-base-uncased/full_grad/inp/adv/1e-05/64/None/model_2",
        "gender": {
            "dev": {
                "ss": 0.6190476190476191,
                "lms": 0.8650793650793651,
                "icat": 0.6591080876795162
            },
            "test": {
                "ss": 0.5625,
                "lms": 0.875,
                "icat": 0.765625
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4434389140271493,
                "lms": 0.8733031674208145,
                "icat": 0.7745132163551115
            },
            "test": {
                "ss": 0.5384615384615384,
                "lms": 0.8868778280542986,
                "icat": 0.8186564566655065
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.5422077922077922,
                "lms": 0.8344155844155844,
                "icat": 0.7639779052116713
            },
            "test": {
                "ss": 0.5032467532467533,
                "lms": 0.827922077922078,
                "icat": 0.8225459605329735
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.5714285714285714,
                "lms": 0.7142857142857143,
                "icat": 0.6122448979591837
            },
            "test": {
                "ss": 0.6363636363636364,
                "lms": 0.8409090909090909,
                "icat": 0.6115702479338844
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4823943661971831,
        "test_criterion_score": -0.543859649122807
    }
}
