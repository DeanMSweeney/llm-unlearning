12/04/2025 09:14:19 - INFO - __main__ - Initialized tokenizer
12/04/2025 09:14:19 - INFO - __main__ - Found 15 models to evaluate.
12/04/2025 09:14:19 - INFO - __main__ - Constructing StereoSet dataloaders
12/04/2025 09:14:19 - INFO - __main__ - Constructed StereoSet dataloaders
12/04/2025 09:14:19 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_7
12/04/2025 09:14:19 - INFO - __main__ - ==================================================1/15==================================================
12/04/2025 09:14:21 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_7",
    "gender": {
        "dev": {
            "ss": 0.6190476190476191,
            "lms": 0.8253968253968254,
            "icat": 0.6288737717309145
        },
        "test": {
            "ss": 0.546875,
            "lms": 0.71875,
            "icat": 0.6513671875
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4253393665158371,
            "lms": 0.7013574660633484,
            "icat": 0.5966298806330746
        },
        "test": {
            "ss": 0.5384615384615384,
            "lms": 0.6787330316742082,
            "icat": 0.6265227984684999
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4935064935064935,
            "lms": 0.7305194805194806,
            "icat": 0.7210322145387081
        },
        "test": {
            "ss": 0.42857142857142855,
            "lms": 0.7045454545454546,
            "icat": 0.6038961038961039
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.7142857142857143,
            "icat": 0.6122448979591837
        },
        "test": {
            "ss": 0.45454545454545453,
            "lms": 0.6590909090909091,
            "icat": 0.5991735537190083
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:21 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:21 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_6
12/04/2025 09:14:21 - INFO - __main__ - ==================================================2/15==================================================
12/04/2025 09:14:22 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_6",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.8333333333333334,
            "icat": 0.6613756613756615
        },
        "test": {
            "ss": 0.5625,
            "lms": 0.71875,
            "icat": 0.62890625
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.43891402714932126,
            "lms": 0.7036199095022625,
            "icat": 0.617657296124158
        },
        "test": {
            "ss": 0.5429864253393665,
            "lms": 0.6855203619909502,
            "icat": 0.6265842222722713
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4935064935064935,
            "lms": 0.7435064935064936,
            "icat": 0.7338505650193963
        },
        "test": {
            "ss": 0.4318181818181818,
            "lms": 0.7142857142857143,
            "icat": 0.6168831168831169
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.7142857142857143,
            "icat": 0.6122448979591837
        },
        "test": {
            "ss": 0.45454545454545453,
            "lms": 0.6136363636363636,
            "icat": 0.5578512396694215
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:22 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:22 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_3
12/04/2025 09:14:22 - INFO - __main__ - ==================================================3/15==================================================
12/04/2025 09:14:23 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_3",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.8650793650793651,
            "icat": 0.6865709246661629
        },
        "test": {
            "ss": 0.546875,
            "lms": 0.7734375,
            "icat": 0.700927734375
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.47058823529411764,
            "lms": 0.753393665158371,
            "icat": 0.7090763907372903
        },
        "test": {
            "ss": 0.5520361990950227,
            "lms": 0.7149321266968326,
            "icat": 0.640527425728384
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4772727272727273,
            "lms": 0.775974025974026,
            "icat": 0.740702479338843
        },
        "test": {
            "ss": 0.42857142857142855,
            "lms": 0.7646103896103896,
            "icat": 0.6553803339517625
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.5238095238095238,
            "lms": 0.7380952380952381,
            "icat": 0.7029478458049887
        },
        "test": {
            "ss": 0.5,
            "lms": 0.7045454545454546,
            "icat": 0.7045454545454546
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:23 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:23 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_8
12/04/2025 09:14:23 - INFO - __main__ - ==================================================4/15==================================================
12/04/2025 09:14:24 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_8",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.8174603174603174,
            "icat": 0.6487780297304108
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.71875,
            "icat": 0.673828125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4253393665158371,
            "lms": 0.6945701357466063,
            "icat": 0.590856043078561
        },
        "test": {
            "ss": 0.5475113122171946,
            "lms": 0.6742081447963801,
            "icat": 0.6101431174627874
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4902597402597403,
            "lms": 0.7256493506493507,
            "icat": 0.7115133243379997
        },
        "test": {
            "ss": 0.4253246753246753,
            "lms": 0.6964285714285714,
            "icat": 0.5924165120593692
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.7142857142857143,
            "icat": 0.6122448979591837
        },
        "test": {
            "ss": 0.45454545454545453,
            "lms": 0.6363636363636364,
            "icat": 0.5785123966942148
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:24 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:24 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_14
12/04/2025 09:14:24 - INFO - __main__ - ==================================================5/15==================================================
12/04/2025 09:14:25 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_14",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.7936507936507936,
            "icat": 0.6298815822625347
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.703125,
            "icat": 0.6591796875
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.38461538461538464,
            "lms": 0.6606334841628959,
            "icat": 0.5081796032022277
        },
        "test": {
            "ss": 0.5339366515837104,
            "lms": 0.6334841628959276,
            "icat": 0.5904875002559326
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4837662337662338,
            "lms": 0.6931818181818182,
            "icat": 0.6706759149940968
        },
        "test": {
            "ss": 0.44155844155844154,
            "lms": 0.6623376623376623,
            "icat": 0.584921571934559
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.6666666666666666,
            "icat": 0.5714285714285714
        },
        "test": {
            "ss": 0.5,
            "lms": 0.6136363636363636,
            "icat": 0.6136363636363636
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:25 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:25 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15
12/04/2025 09:14:25 - INFO - __main__ - ==================================================6/15==================================================
12/04/2025 09:14:26 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
    "gender": {
        "dev": {
            "ss": 0.5873015873015873,
            "lms": 0.7857142857142857,
            "icat": 0.6485260770975056
        },
        "test": {
            "ss": 0.546875,
            "lms": 0.6953125,
            "icat": 0.630126953125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.3755656108597285,
            "lms": 0.6561085972850679,
            "icat": 0.49282365225937225
        },
        "test": {
            "ss": 0.5294117647058824,
            "lms": 0.6266968325791855,
            "icat": 0.589832313015704
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.487012987012987,
            "lms": 0.6915584415584416,
            "icat": 0.6735958846348457
        },
        "test": {
            "ss": 0.4383116883116883,
            "lms": 0.650974025974026,
            "icat": 0.5706590487434643
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.6428571428571429,
            "icat": 0.5510204081632654
        },
        "test": {
            "ss": 0.5,
            "lms": 0.6136363636363636,
            "icat": 0.6136363636363636
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:26 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:26 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_5
12/04/2025 09:14:26 - INFO - __main__ - ==================================================7/15==================================================
12/04/2025 09:14:26 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_5",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.8412698412698413,
            "icat": 0.6676744771982868
        },
        "test": {
            "ss": 0.5625,
            "lms": 0.7265625,
            "icat": 0.6357421875
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4343891402714932,
            "lms": 0.7104072398190046,
            "icat": 0.6171863802952438
        },
        "test": {
            "ss": 0.5475113122171946,
            "lms": 0.6900452488687783,
            "icat": 0.6244753383427857
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4837662337662338,
            "lms": 0.7532467532467533,
            "icat": 0.7287906898296509
        },
        "test": {
            "ss": 0.4253246753246753,
            "lms": 0.7288961038961039,
            "icat": 0.6200349974700624
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.7380952380952381,
            "icat": 0.6326530612244898
        },
        "test": {
            "ss": 0.45454545454545453,
            "lms": 0.7045454545454546,
            "icat": 0.640495867768595
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:26 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:26 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_4
12/04/2025 09:14:26 - INFO - __main__ - ==================================================8/15==================================================
12/04/2025 09:14:27 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_4",
    "gender": {
        "dev": {
            "ss": 0.6190476190476191,
            "lms": 0.8492063492063492,
            "icat": 0.6470143613000755
        },
        "test": {
            "ss": 0.5625,
            "lms": 0.75,
            "icat": 0.65625
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4479638009049774,
            "lms": 0.7285067873303167,
            "icat": 0.6526893388751254
        },
        "test": {
            "ss": 0.5475113122171946,
            "lms": 0.6923076923076923,
            "icat": 0.6265227984684998
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4805194805194805,
            "lms": 0.762987012987013,
            "icat": 0.7332602462472593
        },
        "test": {
            "ss": 0.4253246753246753,
            "lms": 0.7402597402597403,
            "icat": 0.6297014673638051
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.47619047619047616,
            "lms": 0.7380952380952381,
            "icat": 0.7029478458049887
        },
        "test": {
            "ss": 0.45454545454545453,
            "lms": 0.7272727272727273,
            "icat": 0.6611570247933884
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:27 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:27 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_10
12/04/2025 09:14:27 - INFO - __main__ - ==================================================9/15==================================================
12/04/2025 09:14:28 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_10",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.8095238095238095,
            "icat": 0.6424792139077854
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.71875,
            "icat": 0.673828125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4253393665158371,
            "lms": 0.6877828054298643,
            "icat": 0.5850822055240474
        },
        "test": {
            "ss": 0.5384615384615384,
            "lms": 0.6583710407239819,
            "icat": 0.6077271145144448
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.487012987012987,
            "lms": 0.7175324675324676,
            "icat": 0.6988952605835723
        },
        "test": {
            "ss": 0.42207792207792205,
            "lms": 0.689935064935065,
            "icat": 0.5824127171529768
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.6904761904761905,
            "icat": 0.5918367346938775
        },
        "test": {
            "ss": 0.5,
            "lms": 0.6363636363636364,
            "icat": 0.6363636363636364
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:28 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:28 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_1
12/04/2025 09:14:28 - INFO - __main__ - ==================================================10/15==================================================
12/04/2025 09:14:29 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_1",
    "gender": {
        "dev": {
            "ss": 0.6507936507936508,
            "lms": 0.8492063492063492,
            "icat": 0.5930964978584026
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.78125,
            "icat": 0.732421875
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4660633484162896,
            "lms": 0.7941176470588235,
            "icat": 0.7402182592494011
        },
        "test": {
            "ss": 0.5520361990950227,
            "lms": 0.7647058823529411,
            "icat": 0.6851211072664359
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4935064935064935,
            "lms": 0.788961038961039,
            "icat": 0.7787147917018047
        },
        "test": {
            "ss": 0.43506493506493504,
            "lms": 0.7694805194805194,
            "icat": 0.6695479844830493
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.5238095238095238,
            "lms": 0.7380952380952381,
            "icat": 0.7029478458049887
        },
        "test": {
            "ss": 0.5454545454545454,
            "lms": 0.7954545454545454,
            "icat": 0.7231404958677686
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:29 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:29 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_9
12/04/2025 09:14:29 - INFO - __main__ - ==================================================11/15==================================================
12/04/2025 09:14:30 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_9",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.8095238095238095,
            "icat": 0.6424792139077854
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.71875,
            "icat": 0.673828125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4298642533936652,
            "lms": 0.6923076923076923,
            "icat": 0.5951966585450749
        },
        "test": {
            "ss": 0.5429864253393665,
            "lms": 0.6606334841628959,
            "icat": 0.6038369402755882
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.487012987012987,
            "lms": 0.7224025974025974,
            "icat": 0.7036388935739585
        },
        "test": {
            "ss": 0.4253246753246753,
            "lms": 0.6964285714285714,
            "icat": 0.5924165120593692
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.6904761904761905,
            "icat": 0.5918367346938775
        },
        "test": {
            "ss": 0.5,
            "lms": 0.6363636363636364,
            "icat": 0.6363636363636364
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:30 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:30 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_11
12/04/2025 09:14:30 - INFO - __main__ - ==================================================12/15==================================================
12/04/2025 09:14:31 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_11",
    "gender": {
        "dev": {
            "ss": 0.5873015873015873,
            "lms": 0.8095238095238095,
            "icat": 0.6681783824640968
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.7109375,
            "icat": 0.66650390625
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.416289592760181,
            "lms": 0.6809954751131222,
            "icat": 0.5669826580127353
        },
        "test": {
            "ss": 0.5384615384615384,
            "lms": 0.6447963800904978,
            "icat": 0.5951966585450749
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4837662337662338,
            "lms": 0.7142857142857143,
            "icat": 0.6910946196660482
        },
        "test": {
            "ss": 0.4318181818181818,
            "lms": 0.676948051948052,
            "icat": 0.5846369539551358
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.6904761904761905,
            "icat": 0.5918367346938775
        },
        "test": {
            "ss": 0.5,
            "lms": 0.6363636363636364,
            "icat": 0.6363636363636364
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:31 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:31 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_13
12/04/2025 09:14:31 - INFO - __main__ - ==================================================13/15==================================================
12/04/2025 09:14:31 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_13",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.7936507936507936,
            "icat": 0.6298815822625347
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.7109375,
            "icat": 0.66650390625
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.3891402714932127,
            "lms": 0.665158371040724,
            "icat": 0.5176798181855409
        },
        "test": {
            "ss": 0.5339366515837104,
            "lms": 0.6357466063348416,
            "icat": 0.5925963841854179
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4967532467532468,
            "lms": 0.702922077922078,
            "icat": 0.6983576488446619
        },
        "test": {
            "ss": 0.4383116883116883,
            "lms": 0.6688311688311688,
            "icat": 0.5863130376117389
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.6666666666666666,
            "icat": 0.5714285714285714
        },
        "test": {
            "ss": 0.5,
            "lms": 0.6136363636363636,
            "icat": 0.6136363636363636
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:31 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:31 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_2
12/04/2025 09:14:31 - INFO - __main__ - ==================================================14/15==================================================
12/04/2025 09:14:32 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_2",
    "gender": {
        "dev": {
            "ss": 0.6507936507936508,
            "lms": 0.8492063492063492,
            "icat": 0.5930964978584026
        },
        "test": {
            "ss": 0.546875,
            "lms": 0.8125,
            "icat": 0.736328125
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.4660633484162896,
            "lms": 0.7669683257918553,
            "icat": 0.7149116520955755
        },
        "test": {
            "ss": 0.5475113122171946,
            "lms": 0.748868778280543,
            "icat": 0.677709301611351
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.4837662337662338,
            "lms": 0.7938311688311688,
            "icat": 0.7680574295834036
        },
        "test": {
            "ss": 0.42207792207792205,
            "lms": 0.7532467532467533,
            "icat": 0.6358576488446618
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.5238095238095238,
            "lms": 0.7619047619047619,
            "icat": 0.7256235827664398
        },
        "test": {
            "ss": 0.5,
            "lms": 0.7727272727272727,
            "icat": 0.7727272727272727
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:32 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:32 - INFO - __main__ - Evaluating model at ./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_12
12/04/2025 09:14:32 - INFO - __main__ - ==================================================15/15==================================================
12/04/2025 09:14:33 - INFO - __main__ - Got result: {
    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_12",
    "gender": {
        "dev": {
            "ss": 0.6031746031746031,
            "lms": 0.8015873015873016,
            "icat": 0.63618039808516
        },
        "test": {
            "ss": 0.53125,
            "lms": 0.703125,
            "icat": 0.6591796875
        },
        "dev_count": 189,
        "test_count": 192
    },
    "profession": {
        "dev": {
            "ss": 0.40271493212669685,
            "lms": 0.6764705882352942,
            "icat": 0.5448496140537663
        },
        "test": {
            "ss": 0.5384615384615384,
            "lms": 0.6402714932126696,
            "icat": 0.5910198398886182
        },
        "dev_count": 663,
        "test_count": 663
    },
    "race": {
        "dev": {
            "ss": 0.487012987012987,
            "lms": 0.711038961038961,
            "icat": 0.6925704165963906
        },
        "test": {
            "ss": 0.4318181818181818,
            "lms": 0.6704545454545454,
            "icat": 0.5790289256198347
        },
        "dev_count": 924,
        "test_count": 924
    },
    "religion": {
        "dev": {
            "ss": 0.42857142857142855,
            "lms": 0.6666666666666666,
            "icat": 0.5714285714285714
        },
        "test": {
            "ss": 0.5,
            "lms": 0.6363636363636364,
            "icat": 0.6363636363636364
        },
        "dev_count": 63,
        "test_count": 66
    }
}
12/04/2025 09:14:33 - INFO - __main__ - ====================================================================================================
12/04/2025 09:14:33 - INFO - __main__ - Got results map {
    "notall": {
        "inp": {
            "adv": {
                "1e-05": {
                    "64": {
                        "10000": {
                            "model_7": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_7",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6190476190476191,
                                        "lms": 0.8253968253968254,
                                        "icat": 0.6288737717309145
                                    },
                                    "test": {
                                        "ss": 0.546875,
                                        "lms": 0.71875,
                                        "icat": 0.6513671875
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4253393665158371,
                                        "lms": 0.7013574660633484,
                                        "icat": 0.5966298806330746
                                    },
                                    "test": {
                                        "ss": 0.5384615384615384,
                                        "lms": 0.6787330316742082,
                                        "icat": 0.6265227984684999
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4935064935064935,
                                        "lms": 0.7305194805194806,
                                        "icat": 0.7210322145387081
                                    },
                                    "test": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.7045454545454546,
                                        "icat": 0.6038961038961039
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.7142857142857143,
                                        "icat": 0.6122448979591837
                                    },
                                    "test": {
                                        "ss": 0.45454545454545453,
                                        "lms": 0.6590909090909091,
                                        "icat": 0.5991735537190083
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_6": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_6",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.8333333333333334,
                                        "icat": 0.6613756613756615
                                    },
                                    "test": {
                                        "ss": 0.5625,
                                        "lms": 0.71875,
                                        "icat": 0.62890625
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.43891402714932126,
                                        "lms": 0.7036199095022625,
                                        "icat": 0.617657296124158
                                    },
                                    "test": {
                                        "ss": 0.5429864253393665,
                                        "lms": 0.6855203619909502,
                                        "icat": 0.6265842222722713
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4935064935064935,
                                        "lms": 0.7435064935064936,
                                        "icat": 0.7338505650193963
                                    },
                                    "test": {
                                        "ss": 0.4318181818181818,
                                        "lms": 0.7142857142857143,
                                        "icat": 0.6168831168831169
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.7142857142857143,
                                        "icat": 0.6122448979591837
                                    },
                                    "test": {
                                        "ss": 0.45454545454545453,
                                        "lms": 0.6136363636363636,
                                        "icat": 0.5578512396694215
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_3": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_3",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.8650793650793651,
                                        "icat": 0.6865709246661629
                                    },
                                    "test": {
                                        "ss": 0.546875,
                                        "lms": 0.7734375,
                                        "icat": 0.700927734375
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.47058823529411764,
                                        "lms": 0.753393665158371,
                                        "icat": 0.7090763907372903
                                    },
                                    "test": {
                                        "ss": 0.5520361990950227,
                                        "lms": 0.7149321266968326,
                                        "icat": 0.640527425728384
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4772727272727273,
                                        "lms": 0.775974025974026,
                                        "icat": 0.740702479338843
                                    },
                                    "test": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.7646103896103896,
                                        "icat": 0.6553803339517625
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.5238095238095238,
                                        "lms": 0.7380952380952381,
                                        "icat": 0.7029478458049887
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.7045454545454546,
                                        "icat": 0.7045454545454546
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_8": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_8",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.8174603174603174,
                                        "icat": 0.6487780297304108
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.71875,
                                        "icat": 0.673828125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4253393665158371,
                                        "lms": 0.6945701357466063,
                                        "icat": 0.590856043078561
                                    },
                                    "test": {
                                        "ss": 0.5475113122171946,
                                        "lms": 0.6742081447963801,
                                        "icat": 0.6101431174627874
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4902597402597403,
                                        "lms": 0.7256493506493507,
                                        "icat": 0.7115133243379997
                                    },
                                    "test": {
                                        "ss": 0.4253246753246753,
                                        "lms": 0.6964285714285714,
                                        "icat": 0.5924165120593692
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.7142857142857143,
                                        "icat": 0.6122448979591837
                                    },
                                    "test": {
                                        "ss": 0.45454545454545453,
                                        "lms": 0.6363636363636364,
                                        "icat": 0.5785123966942148
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_14": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_14",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.7936507936507936,
                                        "icat": 0.6298815822625347
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.703125,
                                        "icat": 0.6591796875
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.38461538461538464,
                                        "lms": 0.6606334841628959,
                                        "icat": 0.5081796032022277
                                    },
                                    "test": {
                                        "ss": 0.5339366515837104,
                                        "lms": 0.6334841628959276,
                                        "icat": 0.5904875002559326
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4837662337662338,
                                        "lms": 0.6931818181818182,
                                        "icat": 0.6706759149940968
                                    },
                                    "test": {
                                        "ss": 0.44155844155844154,
                                        "lms": 0.6623376623376623,
                                        "icat": 0.584921571934559
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6666666666666666,
                                        "icat": 0.5714285714285714
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6136363636363636,
                                        "icat": 0.6136363636363636
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_15": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
                                "gender": {
                                    "dev": {
                                        "ss": 0.5873015873015873,
                                        "lms": 0.7857142857142857,
                                        "icat": 0.6485260770975056
                                    },
                                    "test": {
                                        "ss": 0.546875,
                                        "lms": 0.6953125,
                                        "icat": 0.630126953125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.3755656108597285,
                                        "lms": 0.6561085972850679,
                                        "icat": 0.49282365225937225
                                    },
                                    "test": {
                                        "ss": 0.5294117647058824,
                                        "lms": 0.6266968325791855,
                                        "icat": 0.589832313015704
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.487012987012987,
                                        "lms": 0.6915584415584416,
                                        "icat": 0.6735958846348457
                                    },
                                    "test": {
                                        "ss": 0.4383116883116883,
                                        "lms": 0.650974025974026,
                                        "icat": 0.5706590487434643
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6428571428571429,
                                        "icat": 0.5510204081632654
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6136363636363636,
                                        "icat": 0.6136363636363636
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_5": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_5",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.8412698412698413,
                                        "icat": 0.6676744771982868
                                    },
                                    "test": {
                                        "ss": 0.5625,
                                        "lms": 0.7265625,
                                        "icat": 0.6357421875
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4343891402714932,
                                        "lms": 0.7104072398190046,
                                        "icat": 0.6171863802952438
                                    },
                                    "test": {
                                        "ss": 0.5475113122171946,
                                        "lms": 0.6900452488687783,
                                        "icat": 0.6244753383427857
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4837662337662338,
                                        "lms": 0.7532467532467533,
                                        "icat": 0.7287906898296509
                                    },
                                    "test": {
                                        "ss": 0.4253246753246753,
                                        "lms": 0.7288961038961039,
                                        "icat": 0.6200349974700624
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.7380952380952381,
                                        "icat": 0.6326530612244898
                                    },
                                    "test": {
                                        "ss": 0.45454545454545453,
                                        "lms": 0.7045454545454546,
                                        "icat": 0.640495867768595
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_4": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_4",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6190476190476191,
                                        "lms": 0.8492063492063492,
                                        "icat": 0.6470143613000755
                                    },
                                    "test": {
                                        "ss": 0.5625,
                                        "lms": 0.75,
                                        "icat": 0.65625
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4479638009049774,
                                        "lms": 0.7285067873303167,
                                        "icat": 0.6526893388751254
                                    },
                                    "test": {
                                        "ss": 0.5475113122171946,
                                        "lms": 0.6923076923076923,
                                        "icat": 0.6265227984684998
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4805194805194805,
                                        "lms": 0.762987012987013,
                                        "icat": 0.7332602462472593
                                    },
                                    "test": {
                                        "ss": 0.4253246753246753,
                                        "lms": 0.7402597402597403,
                                        "icat": 0.6297014673638051
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.47619047619047616,
                                        "lms": 0.7380952380952381,
                                        "icat": 0.7029478458049887
                                    },
                                    "test": {
                                        "ss": 0.45454545454545453,
                                        "lms": 0.7272727272727273,
                                        "icat": 0.6611570247933884
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_10": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_10",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.8095238095238095,
                                        "icat": 0.6424792139077854
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.71875,
                                        "icat": 0.673828125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4253393665158371,
                                        "lms": 0.6877828054298643,
                                        "icat": 0.5850822055240474
                                    },
                                    "test": {
                                        "ss": 0.5384615384615384,
                                        "lms": 0.6583710407239819,
                                        "icat": 0.6077271145144448
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.487012987012987,
                                        "lms": 0.7175324675324676,
                                        "icat": 0.6988952605835723
                                    },
                                    "test": {
                                        "ss": 0.42207792207792205,
                                        "lms": 0.689935064935065,
                                        "icat": 0.5824127171529768
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6904761904761905,
                                        "icat": 0.5918367346938775
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6363636363636364,
                                        "icat": 0.6363636363636364
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_1": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_1",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6507936507936508,
                                        "lms": 0.8492063492063492,
                                        "icat": 0.5930964978584026
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.78125,
                                        "icat": 0.732421875
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4660633484162896,
                                        "lms": 0.7941176470588235,
                                        "icat": 0.7402182592494011
                                    },
                                    "test": {
                                        "ss": 0.5520361990950227,
                                        "lms": 0.7647058823529411,
                                        "icat": 0.6851211072664359
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4935064935064935,
                                        "lms": 0.788961038961039,
                                        "icat": 0.7787147917018047
                                    },
                                    "test": {
                                        "ss": 0.43506493506493504,
                                        "lms": 0.7694805194805194,
                                        "icat": 0.6695479844830493
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.5238095238095238,
                                        "lms": 0.7380952380952381,
                                        "icat": 0.7029478458049887
                                    },
                                    "test": {
                                        "ss": 0.5454545454545454,
                                        "lms": 0.7954545454545454,
                                        "icat": 0.7231404958677686
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_9": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_9",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.8095238095238095,
                                        "icat": 0.6424792139077854
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.71875,
                                        "icat": 0.673828125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4298642533936652,
                                        "lms": 0.6923076923076923,
                                        "icat": 0.5951966585450749
                                    },
                                    "test": {
                                        "ss": 0.5429864253393665,
                                        "lms": 0.6606334841628959,
                                        "icat": 0.6038369402755882
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.487012987012987,
                                        "lms": 0.7224025974025974,
                                        "icat": 0.7036388935739585
                                    },
                                    "test": {
                                        "ss": 0.4253246753246753,
                                        "lms": 0.6964285714285714,
                                        "icat": 0.5924165120593692
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6904761904761905,
                                        "icat": 0.5918367346938775
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6363636363636364,
                                        "icat": 0.6363636363636364
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_11": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_11",
                                "gender": {
                                    "dev": {
                                        "ss": 0.5873015873015873,
                                        "lms": 0.8095238095238095,
                                        "icat": 0.6681783824640968
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.7109375,
                                        "icat": 0.66650390625
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.416289592760181,
                                        "lms": 0.6809954751131222,
                                        "icat": 0.5669826580127353
                                    },
                                    "test": {
                                        "ss": 0.5384615384615384,
                                        "lms": 0.6447963800904978,
                                        "icat": 0.5951966585450749
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4837662337662338,
                                        "lms": 0.7142857142857143,
                                        "icat": 0.6910946196660482
                                    },
                                    "test": {
                                        "ss": 0.4318181818181818,
                                        "lms": 0.676948051948052,
                                        "icat": 0.5846369539551358
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6904761904761905,
                                        "icat": 0.5918367346938775
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6363636363636364,
                                        "icat": 0.6363636363636364
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_13": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_13",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.7936507936507936,
                                        "icat": 0.6298815822625347
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.7109375,
                                        "icat": 0.66650390625
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.3891402714932127,
                                        "lms": 0.665158371040724,
                                        "icat": 0.5176798181855409
                                    },
                                    "test": {
                                        "ss": 0.5339366515837104,
                                        "lms": 0.6357466063348416,
                                        "icat": 0.5925963841854179
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4967532467532468,
                                        "lms": 0.702922077922078,
                                        "icat": 0.6983576488446619
                                    },
                                    "test": {
                                        "ss": 0.4383116883116883,
                                        "lms": 0.6688311688311688,
                                        "icat": 0.5863130376117389
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6666666666666666,
                                        "icat": 0.5714285714285714
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6136363636363636,
                                        "icat": 0.6136363636363636
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_2": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_2",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6507936507936508,
                                        "lms": 0.8492063492063492,
                                        "icat": 0.5930964978584026
                                    },
                                    "test": {
                                        "ss": 0.546875,
                                        "lms": 0.8125,
                                        "icat": 0.736328125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.4660633484162896,
                                        "lms": 0.7669683257918553,
                                        "icat": 0.7149116520955755
                                    },
                                    "test": {
                                        "ss": 0.5475113122171946,
                                        "lms": 0.748868778280543,
                                        "icat": 0.677709301611351
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.4837662337662338,
                                        "lms": 0.7938311688311688,
                                        "icat": 0.7680574295834036
                                    },
                                    "test": {
                                        "ss": 0.42207792207792205,
                                        "lms": 0.7532467532467533,
                                        "icat": 0.6358576488446618
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.5238095238095238,
                                        "lms": 0.7619047619047619,
                                        "icat": 0.7256235827664398
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.7727272727272727,
                                        "icat": 0.7727272727272727
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            },
                            "model_12": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_12",
                                "gender": {
                                    "dev": {
                                        "ss": 0.6031746031746031,
                                        "lms": 0.8015873015873016,
                                        "icat": 0.63618039808516
                                    },
                                    "test": {
                                        "ss": 0.53125,
                                        "lms": 0.703125,
                                        "icat": 0.6591796875
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.40271493212669685,
                                        "lms": 0.6764705882352942,
                                        "icat": 0.5448496140537663
                                    },
                                    "test": {
                                        "ss": 0.5384615384615384,
                                        "lms": 0.6402714932126696,
                                        "icat": 0.5910198398886182
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.487012987012987,
                                        "lms": 0.711038961038961,
                                        "icat": 0.6925704165963906
                                    },
                                    "test": {
                                        "ss": 0.4318181818181818,
                                        "lms": 0.6704545454545454,
                                        "icat": 0.5790289256198347
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6666666666666666,
                                        "icat": 0.5714285714285714
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6363636363636364,
                                        "icat": 0.6363636363636364
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}
12/04/2025 09:14:33 - INFO - __main__ - Got best results {
    "best_model": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
        "gender": {
            "dev": {
                "ss": 0.5873015873015873,
                "lms": 0.7857142857142857,
                "icat": 0.6485260770975056
            },
            "test": {
                "ss": 0.546875,
                "lms": 0.6953125,
                "icat": 0.630126953125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.3755656108597285,
                "lms": 0.6561085972850679,
                "icat": 0.49282365225937225
            },
            "test": {
                "ss": 0.5294117647058824,
                "lms": 0.6266968325791855,
                "icat": 0.589832313015704
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.487012987012987,
                "lms": 0.6915584415584416,
                "icat": 0.6735958846348457
            },
            "test": {
                "ss": 0.4383116883116883,
                "lms": 0.650974025974026,
                "icat": 0.5706590487434643
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6428571428571429,
                "icat": 0.5510204081632654
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6136363636363636,
                "icat": 0.6136363636363636
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4225352112676056,
        "test_criterion_score": -0.5333333333333333
    },
    "notall": {
        "best_model": {
            "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
            "gender": {
                "dev": {
                    "ss": 0.5873015873015873,
                    "lms": 0.7857142857142857,
                    "icat": 0.6485260770975056
                },
                "test": {
                    "ss": 0.546875,
                    "lms": 0.6953125,
                    "icat": 0.630126953125
                },
                "dev_count": 189,
                "test_count": 192
            },
            "profession": {
                "dev": {
                    "ss": 0.3755656108597285,
                    "lms": 0.6561085972850679,
                    "icat": 0.49282365225937225
                },
                "test": {
                    "ss": 0.5294117647058824,
                    "lms": 0.6266968325791855,
                    "icat": 0.589832313015704
                },
                "dev_count": 663,
                "test_count": 663
            },
            "race": {
                "dev": {
                    "ss": 0.487012987012987,
                    "lms": 0.6915584415584416,
                    "icat": 0.6735958846348457
                },
                "test": {
                    "ss": 0.4383116883116883,
                    "lms": 0.650974025974026,
                    "icat": 0.5706590487434643
                },
                "dev_count": 924,
                "test_count": 924
            },
            "religion": {
                "dev": {
                    "ss": 0.42857142857142855,
                    "lms": 0.6428571428571429,
                    "icat": 0.5510204081632654
                },
                "test": {
                    "ss": 0.5,
                    "lms": 0.6136363636363636,
                    "icat": 0.6136363636363636
                },
                "dev_count": 63,
                "test_count": 66
            },
            "dev_criterion_score": -0.4225352112676056,
            "test_criterion_score": -0.5333333333333333
        },
        "inp": {
            "best_model": {
                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
                "gender": {
                    "dev": {
                        "ss": 0.5873015873015873,
                        "lms": 0.7857142857142857,
                        "icat": 0.6485260770975056
                    },
                    "test": {
                        "ss": 0.546875,
                        "lms": 0.6953125,
                        "icat": 0.630126953125
                    },
                    "dev_count": 189,
                    "test_count": 192
                },
                "profession": {
                    "dev": {
                        "ss": 0.3755656108597285,
                        "lms": 0.6561085972850679,
                        "icat": 0.49282365225937225
                    },
                    "test": {
                        "ss": 0.5294117647058824,
                        "lms": 0.6266968325791855,
                        "icat": 0.589832313015704
                    },
                    "dev_count": 663,
                    "test_count": 663
                },
                "race": {
                    "dev": {
                        "ss": 0.487012987012987,
                        "lms": 0.6915584415584416,
                        "icat": 0.6735958846348457
                    },
                    "test": {
                        "ss": 0.4383116883116883,
                        "lms": 0.650974025974026,
                        "icat": 0.5706590487434643
                    },
                    "dev_count": 924,
                    "test_count": 924
                },
                "religion": {
                    "dev": {
                        "ss": 0.42857142857142855,
                        "lms": 0.6428571428571429,
                        "icat": 0.5510204081632654
                    },
                    "test": {
                        "ss": 0.5,
                        "lms": 0.6136363636363636,
                        "icat": 0.6136363636363636
                    },
                    "dev_count": 63,
                    "test_count": 66
                },
                "dev_criterion_score": -0.4225352112676056,
                "test_criterion_score": -0.5333333333333333
            },
            "adv": {
                "best_model": {
                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
                    "gender": {
                        "dev": {
                            "ss": 0.5873015873015873,
                            "lms": 0.7857142857142857,
                            "icat": 0.6485260770975056
                        },
                        "test": {
                            "ss": 0.546875,
                            "lms": 0.6953125,
                            "icat": 0.630126953125
                        },
                        "dev_count": 189,
                        "test_count": 192
                    },
                    "profession": {
                        "dev": {
                            "ss": 0.3755656108597285,
                            "lms": 0.6561085972850679,
                            "icat": 0.49282365225937225
                        },
                        "test": {
                            "ss": 0.5294117647058824,
                            "lms": 0.6266968325791855,
                            "icat": 0.589832313015704
                        },
                        "dev_count": 663,
                        "test_count": 663
                    },
                    "race": {
                        "dev": {
                            "ss": 0.487012987012987,
                            "lms": 0.6915584415584416,
                            "icat": 0.6735958846348457
                        },
                        "test": {
                            "ss": 0.4383116883116883,
                            "lms": 0.650974025974026,
                            "icat": 0.5706590487434643
                        },
                        "dev_count": 924,
                        "test_count": 924
                    },
                    "religion": {
                        "dev": {
                            "ss": 0.42857142857142855,
                            "lms": 0.6428571428571429,
                            "icat": 0.5510204081632654
                        },
                        "test": {
                            "ss": 0.5,
                            "lms": 0.6136363636363636,
                            "icat": 0.6136363636363636
                        },
                        "dev_count": 63,
                        "test_count": 66
                    },
                    "dev_criterion_score": -0.4225352112676056,
                    "test_criterion_score": -0.5333333333333333
                },
                "1e-05": {
                    "best_model": {
                        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
                        "gender": {
                            "dev": {
                                "ss": 0.5873015873015873,
                                "lms": 0.7857142857142857,
                                "icat": 0.6485260770975056
                            },
                            "test": {
                                "ss": 0.546875,
                                "lms": 0.6953125,
                                "icat": 0.630126953125
                            },
                            "dev_count": 189,
                            "test_count": 192
                        },
                        "profession": {
                            "dev": {
                                "ss": 0.3755656108597285,
                                "lms": 0.6561085972850679,
                                "icat": 0.49282365225937225
                            },
                            "test": {
                                "ss": 0.5294117647058824,
                                "lms": 0.6266968325791855,
                                "icat": 0.589832313015704
                            },
                            "dev_count": 663,
                            "test_count": 663
                        },
                        "race": {
                            "dev": {
                                "ss": 0.487012987012987,
                                "lms": 0.6915584415584416,
                                "icat": 0.6735958846348457
                            },
                            "test": {
                                "ss": 0.4383116883116883,
                                "lms": 0.650974025974026,
                                "icat": 0.5706590487434643
                            },
                            "dev_count": 924,
                            "test_count": 924
                        },
                        "religion": {
                            "dev": {
                                "ss": 0.42857142857142855,
                                "lms": 0.6428571428571429,
                                "icat": 0.5510204081632654
                            },
                            "test": {
                                "ss": 0.5,
                                "lms": 0.6136363636363636,
                                "icat": 0.6136363636363636
                            },
                            "dev_count": 63,
                            "test_count": 66
                        },
                        "dev_criterion_score": -0.4225352112676056,
                        "test_criterion_score": -0.5333333333333333
                    },
                    "64": {
                        "best_model": {
                            "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
                            "gender": {
                                "dev": {
                                    "ss": 0.5873015873015873,
                                    "lms": 0.7857142857142857,
                                    "icat": 0.6485260770975056
                                },
                                "test": {
                                    "ss": 0.546875,
                                    "lms": 0.6953125,
                                    "icat": 0.630126953125
                                },
                                "dev_count": 189,
                                "test_count": 192
                            },
                            "profession": {
                                "dev": {
                                    "ss": 0.3755656108597285,
                                    "lms": 0.6561085972850679,
                                    "icat": 0.49282365225937225
                                },
                                "test": {
                                    "ss": 0.5294117647058824,
                                    "lms": 0.6266968325791855,
                                    "icat": 0.589832313015704
                                },
                                "dev_count": 663,
                                "test_count": 663
                            },
                            "race": {
                                "dev": {
                                    "ss": 0.487012987012987,
                                    "lms": 0.6915584415584416,
                                    "icat": 0.6735958846348457
                                },
                                "test": {
                                    "ss": 0.4383116883116883,
                                    "lms": 0.650974025974026,
                                    "icat": 0.5706590487434643
                                },
                                "dev_count": 924,
                                "test_count": 924
                            },
                            "religion": {
                                "dev": {
                                    "ss": 0.42857142857142855,
                                    "lms": 0.6428571428571429,
                                    "icat": 0.5510204081632654
                                },
                                "test": {
                                    "ss": 0.5,
                                    "lms": 0.6136363636363636,
                                    "icat": 0.6136363636363636
                                },
                                "dev_count": 63,
                                "test_count": 66
                            },
                            "dev_criterion_score": -0.4225352112676056,
                            "test_criterion_score": -0.5333333333333333
                        },
                        "10000": {
                            "best_model": {
                                "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
                                "gender": {
                                    "dev": {
                                        "ss": 0.5873015873015873,
                                        "lms": 0.7857142857142857,
                                        "icat": 0.6485260770975056
                                    },
                                    "test": {
                                        "ss": 0.546875,
                                        "lms": 0.6953125,
                                        "icat": 0.630126953125
                                    },
                                    "dev_count": 189,
                                    "test_count": 192
                                },
                                "profession": {
                                    "dev": {
                                        "ss": 0.3755656108597285,
                                        "lms": 0.6561085972850679,
                                        "icat": 0.49282365225937225
                                    },
                                    "test": {
                                        "ss": 0.5294117647058824,
                                        "lms": 0.6266968325791855,
                                        "icat": 0.589832313015704
                                    },
                                    "dev_count": 663,
                                    "test_count": 663
                                },
                                "race": {
                                    "dev": {
                                        "ss": 0.487012987012987,
                                        "lms": 0.6915584415584416,
                                        "icat": 0.6735958846348457
                                    },
                                    "test": {
                                        "ss": 0.4383116883116883,
                                        "lms": 0.650974025974026,
                                        "icat": 0.5706590487434643
                                    },
                                    "dev_count": 924,
                                    "test_count": 924
                                },
                                "religion": {
                                    "dev": {
                                        "ss": 0.42857142857142855,
                                        "lms": 0.6428571428571429,
                                        "icat": 0.5510204081632654
                                    },
                                    "test": {
                                        "ss": 0.5,
                                        "lms": 0.6136363636363636,
                                        "icat": 0.6136363636363636
                                    },
                                    "dev_count": 63,
                                    "test_count": 66
                                },
                                "dev_criterion_score": -0.4225352112676056,
                                "test_criterion_score": -0.5333333333333333
                            },
                            "model_7": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_7",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6190476190476191,
                                            "lms": 0.8253968253968254,
                                            "icat": 0.6288737717309145
                                        },
                                        "test": {
                                            "ss": 0.546875,
                                            "lms": 0.71875,
                                            "icat": 0.6513671875
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4253393665158371,
                                            "lms": 0.7013574660633484,
                                            "icat": 0.5966298806330746
                                        },
                                        "test": {
                                            "ss": 0.5384615384615384,
                                            "lms": 0.6787330316742082,
                                            "icat": 0.6265227984684999
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4935064935064935,
                                            "lms": 0.7305194805194806,
                                            "icat": 0.7210322145387081
                                        },
                                        "test": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.7045454545454546,
                                            "icat": 0.6038961038961039
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.7142857142857143,
                                            "icat": 0.6122448979591837
                                        },
                                        "test": {
                                            "ss": 0.45454545454545453,
                                            "lms": 0.6590909090909091,
                                            "icat": 0.5991735537190083
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.46830985915492956,
                                    "test_criterion_score": -0.5403508771929825
                                }
                            },
                            "model_6": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_6",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.8333333333333334,
                                            "icat": 0.6613756613756615
                                        },
                                        "test": {
                                            "ss": 0.5625,
                                            "lms": 0.71875,
                                            "icat": 0.62890625
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.43891402714932126,
                                            "lms": 0.7036199095022625,
                                            "icat": 0.617657296124158
                                        },
                                        "test": {
                                            "ss": 0.5429864253393665,
                                            "lms": 0.6855203619909502,
                                            "icat": 0.6265842222722713
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4935064935064935,
                                            "lms": 0.7435064935064936,
                                            "icat": 0.7338505650193963
                                        },
                                        "test": {
                                            "ss": 0.4318181818181818,
                                            "lms": 0.7142857142857143,
                                            "icat": 0.6168831168831169
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.7142857142857143,
                                            "icat": 0.6122448979591837
                                        },
                                        "test": {
                                            "ss": 0.45454545454545453,
                                            "lms": 0.6136363636363636,
                                            "icat": 0.5578512396694215
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4753521126760563,
                                    "test_criterion_score": -0.5473684210526316
                                }
                            },
                            "model_3": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_3",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.8650793650793651,
                                            "icat": 0.6865709246661629
                                        },
                                        "test": {
                                            "ss": 0.546875,
                                            "lms": 0.7734375,
                                            "icat": 0.700927734375
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.47058823529411764,
                                            "lms": 0.753393665158371,
                                            "icat": 0.7090763907372903
                                        },
                                        "test": {
                                            "ss": 0.5520361990950227,
                                            "lms": 0.7149321266968326,
                                            "icat": 0.640527425728384
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4772727272727273,
                                            "lms": 0.775974025974026,
                                            "icat": 0.740702479338843
                                        },
                                        "test": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.7646103896103896,
                                            "icat": 0.6553803339517625
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.5238095238095238,
                                            "lms": 0.7380952380952381,
                                            "icat": 0.7029478458049887
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.7045454545454546,
                                            "icat": 0.7045454545454546
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.5,
                                    "test_criterion_score": -0.5508771929824562
                                }
                            },
                            "model_8": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_8",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.8174603174603174,
                                            "icat": 0.6487780297304108
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.71875,
                                            "icat": 0.673828125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4253393665158371,
                                            "lms": 0.6945701357466063,
                                            "icat": 0.590856043078561
                                        },
                                        "test": {
                                            "ss": 0.5475113122171946,
                                            "lms": 0.6742081447963801,
                                            "icat": 0.6101431174627874
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4902597402597403,
                                            "lms": 0.7256493506493507,
                                            "icat": 0.7115133243379997
                                        },
                                        "test": {
                                            "ss": 0.4253246753246753,
                                            "lms": 0.6964285714285714,
                                            "icat": 0.5924165120593692
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.7142857142857143,
                                            "icat": 0.6122448979591837
                                        },
                                        "test": {
                                            "ss": 0.45454545454545453,
                                            "lms": 0.6363636363636364,
                                            "icat": 0.5785123966942148
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4647887323943662,
                                    "test_criterion_score": -0.543859649122807
                                }
                            },
                            "model_14": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_14",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.7936507936507936,
                                            "icat": 0.6298815822625347
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.703125,
                                            "icat": 0.6591796875
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.38461538461538464,
                                            "lms": 0.6606334841628959,
                                            "icat": 0.5081796032022277
                                        },
                                        "test": {
                                            "ss": 0.5339366515837104,
                                            "lms": 0.6334841628959276,
                                            "icat": 0.5904875002559326
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4837662337662338,
                                            "lms": 0.6931818181818182,
                                            "icat": 0.6706759149940968
                                        },
                                        "test": {
                                            "ss": 0.44155844155844154,
                                            "lms": 0.6623376623376623,
                                            "icat": 0.584921571934559
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.6666666666666666,
                                            "icat": 0.5714285714285714
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.6136363636363636,
                                            "icat": 0.6136363636363636
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.43309859154929575,
                                    "test_criterion_score": -0.5333333333333333
                                }
                            },
                            "model_15": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.5873015873015873,
                                            "lms": 0.7857142857142857,
                                            "icat": 0.6485260770975056
                                        },
                                        "test": {
                                            "ss": 0.546875,
                                            "lms": 0.6953125,
                                            "icat": 0.630126953125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.3755656108597285,
                                            "lms": 0.6561085972850679,
                                            "icat": 0.49282365225937225
                                        },
                                        "test": {
                                            "ss": 0.5294117647058824,
                                            "lms": 0.6266968325791855,
                                            "icat": 0.589832313015704
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.487012987012987,
                                            "lms": 0.6915584415584416,
                                            "icat": 0.6735958846348457
                                        },
                                        "test": {
                                            "ss": 0.4383116883116883,
                                            "lms": 0.650974025974026,
                                            "icat": 0.5706590487434643
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.6428571428571429,
                                            "icat": 0.5510204081632654
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.6136363636363636,
                                            "icat": 0.6136363636363636
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4225352112676056,
                                    "test_criterion_score": -0.5333333333333333
                                }
                            },
                            "model_5": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_5",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.8412698412698413,
                                            "icat": 0.6676744771982868
                                        },
                                        "test": {
                                            "ss": 0.5625,
                                            "lms": 0.7265625,
                                            "icat": 0.6357421875
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4343891402714932,
                                            "lms": 0.7104072398190046,
                                            "icat": 0.6171863802952438
                                        },
                                        "test": {
                                            "ss": 0.5475113122171946,
                                            "lms": 0.6900452488687783,
                                            "icat": 0.6244753383427857
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4837662337662338,
                                            "lms": 0.7532467532467533,
                                            "icat": 0.7287906898296509
                                        },
                                        "test": {
                                            "ss": 0.4253246753246753,
                                            "lms": 0.7288961038961039,
                                            "icat": 0.6200349974700624
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.7380952380952381,
                                            "icat": 0.6326530612244898
                                        },
                                        "test": {
                                            "ss": 0.45454545454545453,
                                            "lms": 0.7045454545454546,
                                            "icat": 0.640495867768595
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.47183098591549294,
                                    "test_criterion_score": -0.5508771929824562
                                }
                            },
                            "model_4": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_4",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6190476190476191,
                                            "lms": 0.8492063492063492,
                                            "icat": 0.6470143613000755
                                        },
                                        "test": {
                                            "ss": 0.5625,
                                            "lms": 0.75,
                                            "icat": 0.65625
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4479638009049774,
                                            "lms": 0.7285067873303167,
                                            "icat": 0.6526893388751254
                                        },
                                        "test": {
                                            "ss": 0.5475113122171946,
                                            "lms": 0.6923076923076923,
                                            "icat": 0.6265227984684998
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4805194805194805,
                                            "lms": 0.762987012987013,
                                            "icat": 0.7332602462472593
                                        },
                                        "test": {
                                            "ss": 0.4253246753246753,
                                            "lms": 0.7402597402597403,
                                            "icat": 0.6297014673638051
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.47619047619047616,
                                            "lms": 0.7380952380952381,
                                            "icat": 0.7029478458049887
                                        },
                                        "test": {
                                            "ss": 0.45454545454545453,
                                            "lms": 0.7272727272727273,
                                            "icat": 0.6611570247933884
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4859154929577465,
                                    "test_criterion_score": -0.5508771929824562
                                }
                            },
                            "model_10": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_10",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.8095238095238095,
                                            "icat": 0.6424792139077854
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.71875,
                                            "icat": 0.673828125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4253393665158371,
                                            "lms": 0.6877828054298643,
                                            "icat": 0.5850822055240474
                                        },
                                        "test": {
                                            "ss": 0.5384615384615384,
                                            "lms": 0.6583710407239819,
                                            "icat": 0.6077271145144448
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.487012987012987,
                                            "lms": 0.7175324675324676,
                                            "icat": 0.6988952605835723
                                        },
                                        "test": {
                                            "ss": 0.42207792207792205,
                                            "lms": 0.689935064935065,
                                            "icat": 0.5824127171529768
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.6904761904761905,
                                            "icat": 0.5918367346938775
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.6363636363636364,
                                            "icat": 0.6363636363636364
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4647887323943662,
                                    "test_criterion_score": -0.5368421052631579
                                }
                            },
                            "model_1": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_1",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6507936507936508,
                                            "lms": 0.8492063492063492,
                                            "icat": 0.5930964978584026
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.78125,
                                            "icat": 0.732421875
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4660633484162896,
                                            "lms": 0.7941176470588235,
                                            "icat": 0.7402182592494011
                                        },
                                        "test": {
                                            "ss": 0.5520361990950227,
                                            "lms": 0.7647058823529411,
                                            "icat": 0.6851211072664359
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4935064935064935,
                                            "lms": 0.788961038961039,
                                            "icat": 0.7787147917018047
                                        },
                                        "test": {
                                            "ss": 0.43506493506493504,
                                            "lms": 0.7694805194805194,
                                            "icat": 0.6695479844830493
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.5238095238095238,
                                            "lms": 0.7380952380952381,
                                            "icat": 0.7029478458049887
                                        },
                                        "test": {
                                            "ss": 0.5454545454545454,
                                            "lms": 0.7954545454545454,
                                            "icat": 0.7231404958677686
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.5070422535211268,
                                    "test_criterion_score": -0.5473684210526316
                                }
                            },
                            "model_9": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_9",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.8095238095238095,
                                            "icat": 0.6424792139077854
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.71875,
                                            "icat": 0.673828125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4298642533936652,
                                            "lms": 0.6923076923076923,
                                            "icat": 0.5951966585450749
                                        },
                                        "test": {
                                            "ss": 0.5429864253393665,
                                            "lms": 0.6606334841628959,
                                            "icat": 0.6038369402755882
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.487012987012987,
                                            "lms": 0.7224025974025974,
                                            "icat": 0.7036388935739585
                                        },
                                        "test": {
                                            "ss": 0.4253246753246753,
                                            "lms": 0.6964285714285714,
                                            "icat": 0.5924165120593692
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.6904761904761905,
                                            "icat": 0.5918367346938775
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.6363636363636364,
                                            "icat": 0.6363636363636364
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.46830985915492956,
                                    "test_criterion_score": -0.5403508771929825
                                }
                            },
                            "model_11": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_11",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.5873015873015873,
                                            "lms": 0.8095238095238095,
                                            "icat": 0.6681783824640968
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.7109375,
                                            "icat": 0.66650390625
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.416289592760181,
                                            "lms": 0.6809954751131222,
                                            "icat": 0.5669826580127353
                                        },
                                        "test": {
                                            "ss": 0.5384615384615384,
                                            "lms": 0.6447963800904978,
                                            "icat": 0.5951966585450749
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4837662337662338,
                                            "lms": 0.7142857142857143,
                                            "icat": 0.6910946196660482
                                        },
                                        "test": {
                                            "ss": 0.4318181818181818,
                                            "lms": 0.676948051948052,
                                            "icat": 0.5846369539551358
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.6904761904761905,
                                            "icat": 0.5918367346938775
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.6363636363636364,
                                            "icat": 0.6363636363636364
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.45422535211267606,
                                    "test_criterion_score": -0.5368421052631579
                                }
                            },
                            "model_13": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_13",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.7936507936507936,
                                            "icat": 0.6298815822625347
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.7109375,
                                            "icat": 0.66650390625
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.3891402714932127,
                                            "lms": 0.665158371040724,
                                            "icat": 0.5176798181855409
                                        },
                                        "test": {
                                            "ss": 0.5339366515837104,
                                            "lms": 0.6357466063348416,
                                            "icat": 0.5925963841854179
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4967532467532468,
                                            "lms": 0.702922077922078,
                                            "icat": 0.6983576488446619
                                        },
                                        "test": {
                                            "ss": 0.4383116883116883,
                                            "lms": 0.6688311688311688,
                                            "icat": 0.5863130376117389
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.6666666666666666,
                                            "icat": 0.5714285714285714
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.6136363636363636,
                                            "icat": 0.6136363636363636
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.43661971830985913,
                                    "test_criterion_score": -0.5333333333333333
                                }
                            },
                            "model_2": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_2",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6507936507936508,
                                            "lms": 0.8492063492063492,
                                            "icat": 0.5930964978584026
                                        },
                                        "test": {
                                            "ss": 0.546875,
                                            "lms": 0.8125,
                                            "icat": 0.736328125
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.4660633484162896,
                                            "lms": 0.7669683257918553,
                                            "icat": 0.7149116520955755
                                        },
                                        "test": {
                                            "ss": 0.5475113122171946,
                                            "lms": 0.748868778280543,
                                            "icat": 0.677709301611351
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.4837662337662338,
                                            "lms": 0.7938311688311688,
                                            "icat": 0.7680574295834036
                                        },
                                        "test": {
                                            "ss": 0.42207792207792205,
                                            "lms": 0.7532467532467533,
                                            "icat": 0.6358576488446618
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.5238095238095238,
                                            "lms": 0.7619047619047619,
                                            "icat": 0.7256235827664398
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.7727272727272727,
                                            "icat": 0.7727272727272727
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.5070422535211268,
                                    "test_criterion_score": -0.5473684210526316
                                }
                            },
                            "model_12": {
                                "best_model": {
                                    "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_12",
                                    "gender": {
                                        "dev": {
                                            "ss": 0.6031746031746031,
                                            "lms": 0.8015873015873016,
                                            "icat": 0.63618039808516
                                        },
                                        "test": {
                                            "ss": 0.53125,
                                            "lms": 0.703125,
                                            "icat": 0.6591796875
                                        },
                                        "dev_count": 189,
                                        "test_count": 192
                                    },
                                    "profession": {
                                        "dev": {
                                            "ss": 0.40271493212669685,
                                            "lms": 0.6764705882352942,
                                            "icat": 0.5448496140537663
                                        },
                                        "test": {
                                            "ss": 0.5384615384615384,
                                            "lms": 0.6402714932126696,
                                            "icat": 0.5910198398886182
                                        },
                                        "dev_count": 663,
                                        "test_count": 663
                                    },
                                    "race": {
                                        "dev": {
                                            "ss": 0.487012987012987,
                                            "lms": 0.711038961038961,
                                            "icat": 0.6925704165963906
                                        },
                                        "test": {
                                            "ss": 0.4318181818181818,
                                            "lms": 0.6704545454545454,
                                            "icat": 0.5790289256198347
                                        },
                                        "dev_count": 924,
                                        "test_count": 924
                                    },
                                    "religion": {
                                        "dev": {
                                            "ss": 0.42857142857142855,
                                            "lms": 0.6666666666666666,
                                            "icat": 0.5714285714285714
                                        },
                                        "test": {
                                            "ss": 0.5,
                                            "lms": 0.6363636363636364,
                                            "icat": 0.6363636363636364
                                        },
                                        "dev_count": 63,
                                        "test_count": 66
                                    },
                                    "dev_criterion_score": -0.4471830985915493,
                                    "test_criterion_score": -0.5368421052631579
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}
12/04/2025 09:14:33 - INFO - __main__ - Got all results {
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_7": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_7",
        "gender": {
            "dev": {
                "ss": 0.6190476190476191,
                "lms": 0.8253968253968254,
                "icat": 0.6288737717309145
            },
            "test": {
                "ss": 0.546875,
                "lms": 0.71875,
                "icat": 0.6513671875
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4253393665158371,
                "lms": 0.7013574660633484,
                "icat": 0.5966298806330746
            },
            "test": {
                "ss": 0.5384615384615384,
                "lms": 0.6787330316742082,
                "icat": 0.6265227984684999
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4935064935064935,
                "lms": 0.7305194805194806,
                "icat": 0.7210322145387081
            },
            "test": {
                "ss": 0.42857142857142855,
                "lms": 0.7045454545454546,
                "icat": 0.6038961038961039
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.7142857142857143,
                "icat": 0.6122448979591837
            },
            "test": {
                "ss": 0.45454545454545453,
                "lms": 0.6590909090909091,
                "icat": 0.5991735537190083
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.46830985915492956,
        "test_criterion_score": -0.5403508771929825
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_6": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_6",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.8333333333333334,
                "icat": 0.6613756613756615
            },
            "test": {
                "ss": 0.5625,
                "lms": 0.71875,
                "icat": 0.62890625
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.43891402714932126,
                "lms": 0.7036199095022625,
                "icat": 0.617657296124158
            },
            "test": {
                "ss": 0.5429864253393665,
                "lms": 0.6855203619909502,
                "icat": 0.6265842222722713
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4935064935064935,
                "lms": 0.7435064935064936,
                "icat": 0.7338505650193963
            },
            "test": {
                "ss": 0.4318181818181818,
                "lms": 0.7142857142857143,
                "icat": 0.6168831168831169
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.7142857142857143,
                "icat": 0.6122448979591837
            },
            "test": {
                "ss": 0.45454545454545453,
                "lms": 0.6136363636363636,
                "icat": 0.5578512396694215
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4753521126760563,
        "test_criterion_score": -0.5473684210526316
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_3": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_3",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.8650793650793651,
                "icat": 0.6865709246661629
            },
            "test": {
                "ss": 0.546875,
                "lms": 0.7734375,
                "icat": 0.700927734375
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.47058823529411764,
                "lms": 0.753393665158371,
                "icat": 0.7090763907372903
            },
            "test": {
                "ss": 0.5520361990950227,
                "lms": 0.7149321266968326,
                "icat": 0.640527425728384
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4772727272727273,
                "lms": 0.775974025974026,
                "icat": 0.740702479338843
            },
            "test": {
                "ss": 0.42857142857142855,
                "lms": 0.7646103896103896,
                "icat": 0.6553803339517625
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.5238095238095238,
                "lms": 0.7380952380952381,
                "icat": 0.7029478458049887
            },
            "test": {
                "ss": 0.5,
                "lms": 0.7045454545454546,
                "icat": 0.7045454545454546
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.5,
        "test_criterion_score": -0.5508771929824562
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_8": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_8",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.8174603174603174,
                "icat": 0.6487780297304108
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.71875,
                "icat": 0.673828125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4253393665158371,
                "lms": 0.6945701357466063,
                "icat": 0.590856043078561
            },
            "test": {
                "ss": 0.5475113122171946,
                "lms": 0.6742081447963801,
                "icat": 0.6101431174627874
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4902597402597403,
                "lms": 0.7256493506493507,
                "icat": 0.7115133243379997
            },
            "test": {
                "ss": 0.4253246753246753,
                "lms": 0.6964285714285714,
                "icat": 0.5924165120593692
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.7142857142857143,
                "icat": 0.6122448979591837
            },
            "test": {
                "ss": 0.45454545454545453,
                "lms": 0.6363636363636364,
                "icat": 0.5785123966942148
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4647887323943662,
        "test_criterion_score": -0.543859649122807
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_14": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_14",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.7936507936507936,
                "icat": 0.6298815822625347
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.703125,
                "icat": 0.6591796875
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.38461538461538464,
                "lms": 0.6606334841628959,
                "icat": 0.5081796032022277
            },
            "test": {
                "ss": 0.5339366515837104,
                "lms": 0.6334841628959276,
                "icat": 0.5904875002559326
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4837662337662338,
                "lms": 0.6931818181818182,
                "icat": 0.6706759149940968
            },
            "test": {
                "ss": 0.44155844155844154,
                "lms": 0.6623376623376623,
                "icat": 0.584921571934559
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6666666666666666,
                "icat": 0.5714285714285714
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6136363636363636,
                "icat": 0.6136363636363636
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.43309859154929575,
        "test_criterion_score": -0.5333333333333333
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_15",
        "gender": {
            "dev": {
                "ss": 0.5873015873015873,
                "lms": 0.7857142857142857,
                "icat": 0.6485260770975056
            },
            "test": {
                "ss": 0.546875,
                "lms": 0.6953125,
                "icat": 0.630126953125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.3755656108597285,
                "lms": 0.6561085972850679,
                "icat": 0.49282365225937225
            },
            "test": {
                "ss": 0.5294117647058824,
                "lms": 0.6266968325791855,
                "icat": 0.589832313015704
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.487012987012987,
                "lms": 0.6915584415584416,
                "icat": 0.6735958846348457
            },
            "test": {
                "ss": 0.4383116883116883,
                "lms": 0.650974025974026,
                "icat": 0.5706590487434643
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6428571428571429,
                "icat": 0.5510204081632654
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6136363636363636,
                "icat": 0.6136363636363636
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4225352112676056,
        "test_criterion_score": -0.5333333333333333
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_5": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_5",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.8412698412698413,
                "icat": 0.6676744771982868
            },
            "test": {
                "ss": 0.5625,
                "lms": 0.7265625,
                "icat": 0.6357421875
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4343891402714932,
                "lms": 0.7104072398190046,
                "icat": 0.6171863802952438
            },
            "test": {
                "ss": 0.5475113122171946,
                "lms": 0.6900452488687783,
                "icat": 0.6244753383427857
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4837662337662338,
                "lms": 0.7532467532467533,
                "icat": 0.7287906898296509
            },
            "test": {
                "ss": 0.4253246753246753,
                "lms": 0.7288961038961039,
                "icat": 0.6200349974700624
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.7380952380952381,
                "icat": 0.6326530612244898
            },
            "test": {
                "ss": 0.45454545454545453,
                "lms": 0.7045454545454546,
                "icat": 0.640495867768595
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.47183098591549294,
        "test_criterion_score": -0.5508771929824562
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_4": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_4",
        "gender": {
            "dev": {
                "ss": 0.6190476190476191,
                "lms": 0.8492063492063492,
                "icat": 0.6470143613000755
            },
            "test": {
                "ss": 0.5625,
                "lms": 0.75,
                "icat": 0.65625
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4479638009049774,
                "lms": 0.7285067873303167,
                "icat": 0.6526893388751254
            },
            "test": {
                "ss": 0.5475113122171946,
                "lms": 0.6923076923076923,
                "icat": 0.6265227984684998
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4805194805194805,
                "lms": 0.762987012987013,
                "icat": 0.7332602462472593
            },
            "test": {
                "ss": 0.4253246753246753,
                "lms": 0.7402597402597403,
                "icat": 0.6297014673638051
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.47619047619047616,
                "lms": 0.7380952380952381,
                "icat": 0.7029478458049887
            },
            "test": {
                "ss": 0.45454545454545453,
                "lms": 0.7272727272727273,
                "icat": 0.6611570247933884
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4859154929577465,
        "test_criterion_score": -0.5508771929824562
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_10": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_10",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.8095238095238095,
                "icat": 0.6424792139077854
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.71875,
                "icat": 0.673828125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4253393665158371,
                "lms": 0.6877828054298643,
                "icat": 0.5850822055240474
            },
            "test": {
                "ss": 0.5384615384615384,
                "lms": 0.6583710407239819,
                "icat": 0.6077271145144448
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.487012987012987,
                "lms": 0.7175324675324676,
                "icat": 0.6988952605835723
            },
            "test": {
                "ss": 0.42207792207792205,
                "lms": 0.689935064935065,
                "icat": 0.5824127171529768
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6904761904761905,
                "icat": 0.5918367346938775
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6363636363636364,
                "icat": 0.6363636363636364
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4647887323943662,
        "test_criterion_score": -0.5368421052631579
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_1": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_1",
        "gender": {
            "dev": {
                "ss": 0.6507936507936508,
                "lms": 0.8492063492063492,
                "icat": 0.5930964978584026
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.78125,
                "icat": 0.732421875
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4660633484162896,
                "lms": 0.7941176470588235,
                "icat": 0.7402182592494011
            },
            "test": {
                "ss": 0.5520361990950227,
                "lms": 0.7647058823529411,
                "icat": 0.6851211072664359
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4935064935064935,
                "lms": 0.788961038961039,
                "icat": 0.7787147917018047
            },
            "test": {
                "ss": 0.43506493506493504,
                "lms": 0.7694805194805194,
                "icat": 0.6695479844830493
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.5238095238095238,
                "lms": 0.7380952380952381,
                "icat": 0.7029478458049887
            },
            "test": {
                "ss": 0.5454545454545454,
                "lms": 0.7954545454545454,
                "icat": 0.7231404958677686
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.5070422535211268,
        "test_criterion_score": -0.5473684210526316
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_9": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_9",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.8095238095238095,
                "icat": 0.6424792139077854
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.71875,
                "icat": 0.673828125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4298642533936652,
                "lms": 0.6923076923076923,
                "icat": 0.5951966585450749
            },
            "test": {
                "ss": 0.5429864253393665,
                "lms": 0.6606334841628959,
                "icat": 0.6038369402755882
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.487012987012987,
                "lms": 0.7224025974025974,
                "icat": 0.7036388935739585
            },
            "test": {
                "ss": 0.4253246753246753,
                "lms": 0.6964285714285714,
                "icat": 0.5924165120593692
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6904761904761905,
                "icat": 0.5918367346938775
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6363636363636364,
                "icat": 0.6363636363636364
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.46830985915492956,
        "test_criterion_score": -0.5403508771929825
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_11": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_11",
        "gender": {
            "dev": {
                "ss": 0.5873015873015873,
                "lms": 0.8095238095238095,
                "icat": 0.6681783824640968
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.7109375,
                "icat": 0.66650390625
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.416289592760181,
                "lms": 0.6809954751131222,
                "icat": 0.5669826580127353
            },
            "test": {
                "ss": 0.5384615384615384,
                "lms": 0.6447963800904978,
                "icat": 0.5951966585450749
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4837662337662338,
                "lms": 0.7142857142857143,
                "icat": 0.6910946196660482
            },
            "test": {
                "ss": 0.4318181818181818,
                "lms": 0.676948051948052,
                "icat": 0.5846369539551358
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6904761904761905,
                "icat": 0.5918367346938775
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6363636363636364,
                "icat": 0.6363636363636364
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.45422535211267606,
        "test_criterion_score": -0.5368421052631579
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_13": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_13",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.7936507936507936,
                "icat": 0.6298815822625347
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.7109375,
                "icat": 0.66650390625
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.3891402714932127,
                "lms": 0.665158371040724,
                "icat": 0.5176798181855409
            },
            "test": {
                "ss": 0.5339366515837104,
                "lms": 0.6357466063348416,
                "icat": 0.5925963841854179
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4967532467532468,
                "lms": 0.702922077922078,
                "icat": 0.6983576488446619
            },
            "test": {
                "ss": 0.4383116883116883,
                "lms": 0.6688311688311688,
                "icat": 0.5863130376117389
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6666666666666666,
                "icat": 0.5714285714285714
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6136363636363636,
                "icat": 0.6136363636363636
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.43661971830985913,
        "test_criterion_score": -0.5333333333333333
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_2": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_2",
        "gender": {
            "dev": {
                "ss": 0.6507936507936508,
                "lms": 0.8492063492063492,
                "icat": 0.5930964978584026
            },
            "test": {
                "ss": 0.546875,
                "lms": 0.8125,
                "icat": 0.736328125
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.4660633484162896,
                "lms": 0.7669683257918553,
                "icat": 0.7149116520955755
            },
            "test": {
                "ss": 0.5475113122171946,
                "lms": 0.748868778280543,
                "icat": 0.677709301611351
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.4837662337662338,
                "lms": 0.7938311688311688,
                "icat": 0.7680574295834036
            },
            "test": {
                "ss": 0.42207792207792205,
                "lms": 0.7532467532467533,
                "icat": 0.6358576488446618
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.5238095238095238,
                "lms": 0.7619047619047619,
                "icat": 0.7256235827664398
            },
            "test": {
                "ss": 0.5,
                "lms": 0.7727272727272727,
                "icat": 0.7727272727272727
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.5070422535211268,
        "test_criterion_score": -0.5473684210526316
    },
    "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_12": {
        "path": "./models/bert-base-uncased/notall/inp/adv/1e-05/64/10000/model_12",
        "gender": {
            "dev": {
                "ss": 0.6031746031746031,
                "lms": 0.8015873015873016,
                "icat": 0.63618039808516
            },
            "test": {
                "ss": 0.53125,
                "lms": 0.703125,
                "icat": 0.6591796875
            },
            "dev_count": 189,
            "test_count": 192
        },
        "profession": {
            "dev": {
                "ss": 0.40271493212669685,
                "lms": 0.6764705882352942,
                "icat": 0.5448496140537663
            },
            "test": {
                "ss": 0.5384615384615384,
                "lms": 0.6402714932126696,
                "icat": 0.5910198398886182
            },
            "dev_count": 663,
            "test_count": 663
        },
        "race": {
            "dev": {
                "ss": 0.487012987012987,
                "lms": 0.711038961038961,
                "icat": 0.6925704165963906
            },
            "test": {
                "ss": 0.4318181818181818,
                "lms": 0.6704545454545454,
                "icat": 0.5790289256198347
            },
            "dev_count": 924,
            "test_count": 924
        },
        "religion": {
            "dev": {
                "ss": 0.42857142857142855,
                "lms": 0.6666666666666666,
                "icat": 0.5714285714285714
            },
            "test": {
                "ss": 0.5,
                "lms": 0.6363636363636364,
                "icat": 0.6363636363636364
            },
            "dev_count": 63,
            "test_count": 66
        },
        "dev_criterion_score": -0.4471830985915493,
        "test_criterion_score": -0.5368421052631579
    }
}
